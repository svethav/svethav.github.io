<!DOCTYPE HTML>
<html>
<head>
<title>JabRef references</title>
<meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<script type="text/javascript">
<!--
// QuickSearch script for JabRef HTML export 
// Version: 3.0
//
// Copyright (c) 2006-2011, Mark Schenk
//
// This software is distributed under a Creative Commons Attribution 3.0 License
// http://creativecommons.org/licenses/by/3.0/
//
// Features:
// - intuitive find-as-you-type searching
//    ~ case insensitive
//    ~ ignore diacritics (optional)
//
// - search with/without Regular Expressions
// - match BibTeX key
//

// Search settings
var searchAbstract = true;	// search in abstract
var searchReview = true;	// search in review

var noSquiggles = true; 	// ignore diacritics when searching
var searchRegExp = false; 	// enable RegExp searches


if (window.addEventListener) {
	window.addEventListener("load",initSearch,false); }
else if (window.attachEvent) {
	window.attachEvent("onload", initSearch); }

function initSearch() {
	// check for quick search table and searchfield
	if (!document.getElementById('qs_table')||!document.getElementById('quicksearch')) { return; }

	// load all the rows and sort into arrays
	loadTableData();
	
	//find the query field
	qsfield = document.getElementById('qs_field');

	// previous search term; used for speed optimisation
	prevSearch = '';

	//find statistics location
	stats = document.getElementById('stat');
	setStatistics(-1);
	
	// set up preferences
	initPreferences();

	// shows the searchfield
	document.getElementById('quicksearch').style.display = 'block';
	document.getElementById('qs_field').onkeyup = quickSearch;
}

function loadTableData() {
	// find table and appropriate rows
	searchTable = document.getElementById('qs_table');
	var allRows = searchTable.getElementsByTagName('tbody')[0].getElementsByTagName('tr');

	// split all rows into entryRows and infoRows (e.g. abstract, review, bibtex)
	entryRows = new Array(); infoRows = new Array(); absRows = new Array(); revRows = new Array();

	// get data from each row
	entryRowsData = new Array(); absRowsData = new Array(); revRowsData = new Array(); 
	
	BibTeXKeys = new Array();
	
	for (var i=0, k=0, j=0; i<allRows.length;i++) {
		if (allRows[i].className.match(/entry/)) {
			entryRows[j] = allRows[i];
			entryRowsData[j] = stripDiacritics(getTextContent(allRows[i]));
			allRows[i].id ? BibTeXKeys[j] = allRows[i].id : allRows[i].id = 'autokey_'+j;
			j ++;
		} else {
			infoRows[k++] = allRows[i];
			// check for abstract/review
			if (allRows[i].className.match(/abstract/)) {
				absRows.push(allRows[i]);
				absRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			} else if (allRows[i].className.match(/review/)) {
				revRows.push(allRows[i]);
				revRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			}
		}
	}
	//number of entries and rows
	numEntries = entryRows.length;
	numInfo = infoRows.length;
	numAbs = absRows.length;
	numRev = revRows.length;
}

function quickSearch(){
	
	tInput = qsfield;

	if (tInput.value.length == 0) {
		showAll();
		setStatistics(-1);
		qsfield.className = '';
		return;
	} else {
		t = stripDiacritics(tInput.value);

		if(!searchRegExp) { t = escapeRegExp(t); }
			
		// only search for valid RegExp
		try {
			textRegExp = new RegExp(t,"i");
			closeAllInfo();
			qsfield.className = '';
		}
			catch(err) {
			prevSearch = tInput.value;
			qsfield.className = 'invalidsearch';
			return;
		}
	}
	
	// count number of hits
	var hits = 0;

	// start looping through all entry rows
	for (var i = 0; cRow = entryRows[i]; i++){

		// only show search the cells if it isn't already hidden OR if the search term is getting shorter, then search all
		if(cRow.className.indexOf('noshow')==-1 || tInput.value.length <= prevSearch.length){
			var found = false; 

			if (entryRowsData[i].search(textRegExp) != -1 || BibTeXKeys[i].search(textRegExp) != -1){ 
				found = true;
			} else {
				if(searchAbstract && absRowsData[i]!=undefined) {
					if (absRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
				if(searchReview && revRowsData[i]!=undefined) {
					if (revRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
			}
			
			if (found){
				cRow.className = 'entry show';
				hits++;
			} else {
				cRow.className = 'entry noshow';
			}
		}
	}

	// update statistics
	setStatistics(hits)
	
	// set previous search value
	prevSearch = tInput.value;
}


// Strip Diacritics from text
// http://stackoverflow.com/questions/990904/javascript-remove-accents-in-strings

// String containing replacement characters for stripping accents 
var stripstring = 
    'AAAAAAACEEEEIIII'+
    'DNOOOOO.OUUUUY..'+
    'aaaaaaaceeeeiiii'+
    'dnooooo.ouuuuy.y'+
    'AaAaAaCcCcCcCcDd'+
    'DdEeEeEeEeEeGgGg'+
    'GgGgHhHhIiIiIiIi'+
    'IiIiJjKkkLlLlLlL'+
    'lJlNnNnNnnNnOoOo'+
    'OoOoRrRrRrSsSsSs'+
    'SsTtTtTtUuUuUuUu'+
    'UuUuWwYyYZzZzZz.';

function stripDiacritics(str){

    if(noSquiggles==false){
        return str;
    }

    var answer='';
    for(var i=0;i<str.length;i++){
        var ch=str[i];
        var chindex=ch.charCodeAt(0)-192;   // Index of character code in the strip string
        if(chindex>=0 && chindex<stripstring.length){
            // Character is within our table, so we can strip the accent...
            var outch=stripstring.charAt(chindex);
            // ...unless it was shown as a '.'
            if(outch!='.')ch=outch;
        }
        answer+=ch;
    }
    return answer;
}

// http://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
// NOTE: must escape every \ in the export code because of the JabRef Export...
function escapeRegExp(str) {
  return str.replace(/[-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
}

function toggleInfo(articleid,info) {

	var entry = document.getElementById(articleid);
	var abs = document.getElementById('abs_'+articleid);
	var rev = document.getElementById('rev_'+articleid);
	var bib = document.getElementById('bib_'+articleid);
	
	if (abs && info == 'abstract') {
		abs.className.indexOf('noshow') == -1?abs.className = 'abstract noshow':abs.className = 'abstract show';
	} else if (rev && info == 'review') {
		rev.className.indexOf('noshow') == -1?rev.className = 'review noshow':rev.className = 'review show';
	} else if (bib && info == 'bibtex') {
		bib.className.indexOf('noshow') == -1?bib.className = 'bibtex noshow':bib.className = 'bibtex show';
	} else { 
		return;
	}

	// check if one or the other is available
	var revshow; var absshow; var bibshow;
	(abs && abs.className.indexOf('noshow') == -1)? absshow = true: absshow = false;
	(rev && rev.className.indexOf('noshow') == -1)? revshow = true: revshow = false;	
	(bib && bib.className.indexOf('noshow') == -1)? bibshow = true: bibshow = false;
	
	// highlight original entry
	if(entry) {
		if (revshow || absshow || bibshow) {
		entry.className = 'entry highlight show';
		} else {
		entry.className = 'entry show';
		}
	}
	
	// When there's a combination of abstract/review/bibtex showing, need to add class for correct styling
	if(absshow) {
		(revshow||bibshow)?abs.className = 'abstract nextshow':abs.className = 'abstract';
	} 
	if (revshow) {
		bibshow?rev.className = 'review nextshow': rev.className = 'review';
	}	
	
}

function setStatistics (hits) {
	if(hits < 0) { hits=numEntries; }
	if(stats) { stats.firstChild.data = hits + '/' + numEntries}
}

function getTextContent(node) {
	// Function written by Arve Bersvendsen
	// http://www.virtuelvis.com
	
	if (node.nodeType == 3) {
	return node.nodeValue;
	} // text node
	if (node.nodeType == 1 && node.className != "infolinks") { // element node
	var text = [];
	for (var chld = node.firstChild;chld;chld=chld.nextSibling) {
		text.push(getTextContent(chld));
	}
	return text.join("");
	} return ""; // some other node, won't contain text nodes.
}

function showAll(){
	closeAllInfo();
	for (var i = 0; i < numEntries; i++){ entryRows[i].className = 'entry show'; }
}

function closeAllInfo(){
	for (var i=0; i < numInfo; i++){
		if (infoRows[i].className.indexOf('noshow') ==-1) {
			infoRows[i].className = infoRows[i].className + ' noshow';
		}
	}
}

function clearQS() {
	qsfield.value = '';
	showAll();
}

function redoQS(){
	showAll();
	quickSearch(qsfield);
}

function updateSetting(obj){
	var option = obj.id;
	var checked = obj.value;

	switch(option)
	 {
	 case "opt_searchAbs":
	   searchAbstract=!searchAbstract;
	   redoQS();
	   break;
	 case "opt_searchRev":
	   searchReview=!searchReview;
	   redoQS();
	   break;
	 case "opt_useRegExp":
	   searchRegExp=!searchRegExp;
	   redoQS();
	   break;
	 case "opt_noAccents":
	   noSquiggles=!noSquiggles;
	   loadTableData();
	   redoQS();
	   break;
	 }
}

function initPreferences(){
	if(searchAbstract){document.getElementById("opt_searchAbs").checked = true;}
	if(searchReview){document.getElementById("opt_searchRev").checked = true;}
	if(noSquiggles){document.getElementById("opt_noAccents").checked = true;}
	if(searchRegExp){document.getElementById("opt_useRegExp").checked = true;}
	
	if(numAbs==0) {document.getElementById("opt_searchAbs").parentNode.style.display = 'none';}
	if(numRev==0) {document.getElementById("opt_searchRev").parentNode.style.display = 'none';}	
}

function toggleSettings(){
	var togglebutton = document.getElementById('showsettings');
	var settings = document.getElementById('settings');
	
	if(settings.className == "hidden"){
		settings.className = "show";
		togglebutton.innerText = "close settings";
		togglebutton.textContent = "close settings";
	}else{
		settings.className = "hidden";
		togglebutton.innerText = "settings...";		
		togglebutton.textContent = "settings...";
	}
}

-->
</script>
<style type="text/css">
body { background-color: white; font-family: Arial, sans-serif; font-size: 13px; line-height: 1.2; padding: 1em; color: #2E2E2E; width: 50em; margin: auto auto; }

form#quicksearch { width: auto; border-style: solid; border-color: gray; border-width: 1px 0px; padding: 0.7em 0.5em; display:none; position:relative; }
span#searchstat {padding-left: 1em;}

div#settings { margin-top:0.7em; /* border-bottom: 1px transparent solid; background-color: #efefef; border: 1px grey solid; */ }
div#settings ul {margin: 0; padding: 0; }
div#settings li {margin: 0; padding: 0 1em 0 0; display: inline; list-style: none; }
div#settings li + li { border-left: 2px #efefef solid; padding-left: 0.5em;}
div#settings input { margin-bottom: 0px;}

div#settings.hidden {display:none;}

#showsettings { border: 1px grey solid; padding: 0 0.5em; float:right; line-height: 1.6em; text-align: right; }
#showsettings:hover { cursor: pointer; }

.invalidsearch { background-color: red; }
input[type="button"] { background-color: #efefef; border: 1px #2E2E2E solid;}

table { border: 1px gray none; width: 100%; empty-cells: show; border-spacing: 0em 0.1em; margin: 1em 0em; }
th, td { border: none; padding: 0.5em; vertical-align: top; text-align: justify; }

td a { color: navy; text-decoration: none; }
td a:hover  { text-decoration: underline; }

tr.noshow { display: none;}
tr.highlight td { background-color: #EFEFEF; border-top: 2px #2E2E2E solid; font-weight: bold; }
tr.abstract td, tr.review td, tr.bibtex td { background-color: #EFEFEF; text-align: justify; border-bottom: 2px #2E2E2E solid; }
tr.nextshow td { border-bottom-style: none; }

tr.bibtex pre { width: 100%; overflow: auto; white-space: pre-wrap;}
p.infolinks { margin: 0.3em 0em 0em 0em; padding: 0px; }

@media print {
	p.infolinks, #qs_settings, #quicksearch, t.bibtex { display: none !important; }
	tr { page-break-inside: avoid; }
}
</style>
</head>
<body>

<form action="" id="quicksearch">
<input type="text" id="qs_field" autocomplete="off" placeholder="Type to search..." /> <input type="button" onclick="clearQS()" value="clear" />
<span id="searchstat">Matching entries: <span id="stat">0</span></span>
<div id="showsettings" onclick="toggleSettings()">settings...</div>
<div id="settings" class="hidden">
<ul>
<li><input type="checkbox" class="search_setting" id="opt_searchAbs" onchange="updateSetting(this)"><label for="opt_searchAbs"> include abstract</label></li>
<li><input type="checkbox" class="search_setting" id="opt_searchRev" onchange="updateSetting(this)"><label for="opt_searchRev"> include review</label></li>
<li><input type="checkbox" class="search_setting" id="opt_useRegExp" onchange="updateSetting(this)"><label for="opt_useRegExp"> use RegExp</label></li>
<li><input type="checkbox" class="search_setting" id="opt_noAccents" onchange="updateSetting(this)"><label for="opt_noAccents"> ignore accents</label></li>
</ul>
</div>
</form>
<table id="qs_table" border="1">
<tbody>
<tr id="beykikhoshk_etal_dsaa16analysing" class="entry">
	<td>Beykikhoshk A, Arandjelovic O, Venkatesh S and Phung D (2016), <i>"Analysing the History of Autism Spectrum Disorder using Topic Models"</i>, In Proceedings of the 3rd International Conference on Data Science and Advanced Analytics (DSAA '16)., Oct., 2016. , pp. 762-771.
	<p class="infolinks">[<a href="javascript:toggleInfo('beykikhoshk_etal_dsaa16analysing','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('beykikhoshk_etal_dsaa16analysing','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="abs_beykikhoshk_etal_dsaa16analysing" class="abstract noshow">
	<td><b>Abstract</b>: We describe a novel framework for the discovery of underlying topics of a longitudinal collection of scholarly data, and the tracking of their lifetime and popularity over time. Unlike the social media or news data, as the topic nuances in science result in new scientific directions to emerge, a new approach to model the longitudinal literature data is using topics which remain identifiable over the course of time. Current studies either disregard the time dimension or treat it as an exchangeable covariate when they fix the topics over time or do not share the topics over epochs when they model the time naturally. We address these issues by adopting a non-parametric Bayesian approach. We assume the data is partially exchangeable and divide it into consecutive epochs. Then, by fixing the topics in a recurrent Chinese restaurant franchise, we impose a static topical structure on the corpus such that the they are shared across epochs and the documents within epochs. We demonstrate the effectiveness of the proposed framework on a collection of medical literature related to autism spectrum disorder. We collect a large corpus of publications and carefully examining two important research issues of the domain as case studies. Moreover, we make the results of our experiment and the source code of the model, freely available to aid other researchers by analysing the results or applying the model to their data collections.</td>
</tr>
<tr id="bib_beykikhoshk_etal_dsaa16analysing" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{beykikhoshk_etal_dsaa16analysing,
  author = {Beykikhoshk, Adham and Arandjelovic, Ognjen and Venkatesh, Svetha and Phung, Dinh},
  title = {Analysing the History of Autism Spectrum Disorder using Topic Models},
  booktitle = {Proceedings of the 3rd International Conference on Data Science and Advanced Analytics (DSAA '16)},
  year = {2016},
  pages = {762--771}
}
</pre></td>
</tr>
<tr id="bo2016effect" class="entry">
	<td>Dao B, Nguyen T, Venkatesh S and Phung D (2016), <i>"Effect of Social Capital on Emotion, Language Style and Latent Topics in Online Depression Community"</i>, In 12th IEEE-RIVF International Conference on Computing and Communication Technologies. , pp. 61-66.
	<p class="infolinks"> [<a href="javascript:toggleInfo('bo2016effect','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_bo2016effect" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{bo2016effect,
  author = {Dao, Bo and Nguyen, Thin and Venkatesh, Svetha and Phung, Dinh},
  title = {Effect of Social Capital on Emotion, Language Style and Latent Topics in Online Depression Community},
  booktitle = {12th IEEE-RIVF International Conference on Computing and Communication Technologies},
  year = {2016},
  pages = {61--66}
}
</pre></td>
</tr>
<tr id="chandan2016predicting" class="entry">
	<td>Karmakar C, Luo W, Tran T, Berk M and Venkatesh S (2016), <i>"Predicting Risk of Suicide Attempt Using History of Physical Illnesses From Electronic Medical Records"</i>, JMIR Mental Health., Jul, 2016.  Vol. 3(3), pp. e19.
	<p class="infolinks">[<a href="javascript:toggleInfo('chandan2016predicting','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('chandan2016predicting','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.2196/mental.5475" target="_blank">DOI</a>] [<a href="http://mental.jmir.org/2016/3/e19/" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_chandan2016predicting" class="abstract noshow">
	<td><b>Abstract</b>: Background: Although physical illnesses, routinely documented in electronic medical records (EMR), have been found to be a contributing factor to suicides, no automated systems use this information to predict suicide risk. Objective: The aim of this study is to quantify the impact of physical illnesses on suicide risk, and develop a predictive model that captures this relationship using EMR data. Methods: We used history of physical illnesses (except chapter V: Mental and behavioral disorders) from EMR data over different time-periods to build a lookup table that contains the probability of suicide risk for each chapter of the International Statistical Classification of Diseases and Related Health Problems, 10th Revision (ICD-10) codes. The lookup table was then used to predict the probability of suicide risk for any new assessment. Based on the different lengths of history of physical illnesses, we developed six different models to predict suicide risk. We tested the performance of developed models to predict 90-day risk using historical data over differing time-periods ranging from 3 to 48 months. A total of 16,858 assessments from 7399 mental health patients with at least one risk assessment was used for the validation of the developed model. The performance was measured using area under the receiver operating characteristic curve (AUC). Results: The best predictive results were derived (AUC=0.71) using combined data across all time-periods, which significantly outperformed the clinical baseline derived from routine risk assessment (AUC=0.56). The proposed approach thus shows potential to be incorporated in the broader risk assessment processes used by clinicians. Conclusions: This study provides a novel approach to exploit the history of physical illnesses extracted from EMR (ICD-10 codes without chapter V-mental and behavioral disorders) to predict suicide risk, and this model outperforms existing clinical assessments of suicide risk.</td>
</tr>
<tr id="bib_chandan2016predicting" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{chandan2016predicting,
  author = {Karmakar, Chandan and Luo, Wei and Tran, Truyen and Berk, Michael and Venkatesh, Svetha},
  title = {Predicting Risk of Suicide Attempt Using History of Physical Illnesses From Electronic Medical Records},
  journal = {JMIR Mental Health},
  year = {2016},
  volume = {3},
  number = {3},
  pages = {e19},
  url = {http://mental.jmir.org/2016/3/e19/},
  doi = {10.2196/mental.5475}
}
</pre></td>
</tr>
<tr id="Cheng2016data" class="entry">
	<td>Li C, Rana S, Phung D and Venkatesh S (2016), <i>"Data clustering using side information dependent Chinese restaurant processes"</i>, Knowledge and Information Systems.  Vol. 47(2), pp. 463-488.
	<p class="infolinks">[<a href="javascript:toggleInfo('Cheng2016data','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Cheng2016data','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1007/s10115-015-0834-7" target="_blank">DOI</a>] [<a href="http://dx.doi.org/10.1007/s10115-015-0834-7" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Cheng2016data" class="abstract noshow">
	<td><b>Abstract</b>: Side information, or auxiliary information associated with documents or image content, provides hints for clustering. We propose a new model, side information dependent Chinese restaurant process, which exploits side information in a Bayesian nonparametric model to improve data clustering. We introduce side information into the framework of distance dependent Chinese restaurant process using a robust decay function to handle noisy side information. The threshold parameter of the decay function is updated automatically in the Gibbs sampling process. A fast inference algorithm is proposed. We evaluate our approach on four datasets: Cora, 20 Newsgroups, NUS-WIDE and one medical dataset. Types of side information explored in this paper include citations, authors, tags, keywords and auxiliary clinical information. The comparison with the state-of-the-art approaches based on standard performance measures (NMI, F1) clearly shows the superiority of our approach.</td>
</tr>
<tr id="bib_Cheng2016data" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{Cheng2016data,
  author = {Li, Cheng and Rana, Santu and Phung, Dinh and Venkatesh, Svetha},
  title = {Data clustering using side information dependent Chinese restaurant processes},
  journal = {Knowledge and Information Systems},
  year = {2016},
  volume = {47},
  number = {2},
  pages = {463--488},
  url = {http://dx.doi.org/10.1007/s10115-015-0834-7},
  doi = {10.1007/s10115-015-0834-7}
}
</pre></td>
</tr>
<tr id="Cheng2016Dirichlet" class="entry">
	<td>Li C, Rana S, Phung D and Venkatesh S (2016), <i>"Dirichlet Process Mixture Models with Pairwise Constraints for Data Clustering"</i>, Annals of Data Science.  Vol. 3(2), pp. 205-223.
	<p class="infolinks">[<a href="javascript:toggleInfo('Cheng2016Dirichlet','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Cheng2016Dirichlet','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1007/s40745-016-0082-z" target="_blank">DOI</a>] [<a href="http://dx.doi.org/10.1007/s40745-016-0082-z" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Cheng2016Dirichlet" class="abstract noshow">
	<td><b>Abstract</b>: The Dirichlet process mixture (DPM) model, a typical Bayesian nonparametric model, can infer the number of clusters automatically, and thus performing priority in data clustering. This paper investigates the influence of pairwise constraints in the DPM model. The pairwise constraint, known as two types: must-link (ML) and cannot-link (CL) constraints, indicates the relationship between two data points. We have proposed two relevant models which incorporate pairwise constraints: the constrained DPM (C-DPM) and the constrained DPM with selected constraints (SC-DPM). In C-DPM, the concept of chunklet is introduced. ML constraints are compiled into chunklets and CL constraints exist between chunklets. We derive the Gibbs sampling of the C-DPM based on chunklets. We further propose a principled approach to select the most useful constraints, which will be incorporated into the SC-DPM. We evaluate the proposed models based on three real datasets: 20 Newsgroups dataset, NUS-WIDE image dataset and Facebook comments datasets we collected by ourselves. Our SC-DPM performs priority in data clustering. In addition, our SC-DPM can be potentially used for short-text clustering.</td>
</tr>
<tr id="bib_Cheng2016Dirichlet" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{Cheng2016Dirichlet,
  author = {Li, Cheng and Rana, Santu and Phung, Dinh and Venkatesh, Svetha},
  title = {Dirichlet Process Mixture Models with Pairwise Constraints for Data Clustering},
  journal = {Annals of Data Science},
  year = {2016},
  volume = {3},
  number = {2},
  pages = {205--223},
  url = {http://dx.doi.org/10.1007/s40745-016-0082-z},
  doi = {10.1007/s40745-016-0082-z}
}
</pre></td>
</tr>
<tr id="cheng2016HierarchialBayesian" class="entry">
	<td>Li C, Rana S, Phung D and Venkatesh S (2016), <i>"Hierarchical Bayesian nonparametric models for knowledge discovery from electronic medical records "</i>, Knowledge-Based Systems .  Vol. 99, pp. 168 - 182.
	<p class="infolinks">[<a href="javascript:toggleInfo('cheng2016HierarchialBayesian','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('cheng2016HierarchialBayesian','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1016/j.knosys.2016.02.005" target="_blank">DOI</a>] [<a href="http://www.sciencedirect.com/science/article/pii/S0950705116000836" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_cheng2016HierarchialBayesian" class="abstract noshow">
	<td><b>Abstract</b>: Abstract Electronic Medical Record (EMR) has established itself as a valuable resource for large scale analysis of health data. A hospital EMR\ dataset typically consists of medical records of hospitalized patients. A medical record contains diagnostic information (diagnosis codes), procedures performed (procedure codes) and admission details. Traditional topic models, such as latent Dirichlet allocation (LDA) and hierarchical Dirichlet process (HDP), can be employed to discover disease topics from EMR\ data by treating patients as documents and diagnosis codes as words. This topic modeling helps to understand the constitution of patient diseases and offers a tool for better planning of treatment. In this paper, we propose a novel and flexible hierarchical Bayesian nonparametric model, the word distance dependent Chinese restaurant franchise (wddCRF), which incorporates word-to-word distances to discover semantically-coherent disease topics. We are motivated by the fact that diagnosis codes are connected in the form of ICD-10 tree structure which presents semantic relationships between codes. We exploit a decay function to incorporate distances between words at the bottom level of wddCRF. Efficient inference is derived for the wddCRF by using MCMC\ technique. Furthermore, since procedure codes are often correlated with diagnosis codes, we develop the correspondence wddCRF (Corr-wddCRF) to explore conditional relationships of procedure codes for a given disease pattern. Efficient collapsed Gibbs sampling is derived for the Corr-wddCRF. We evaluate the proposed models on two real-world medical datasets – PolyVascular disease and Acute Myocardial Infarction disease. We demonstrate that the Corr-wddCRF model discovers more coherent topics than the Corr-HDP. We also use disease topic proportions as new features and show that using features from the Corr-wddCRF outperforms the baselines on 14-days readmission prediction. Beside these, the prediction for procedure codes based on the Corr-wddCRF also shows considerable accuracy.</td>
</tr>
<tr id="bib_cheng2016HierarchialBayesian" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{cheng2016HierarchialBayesian,
  author = {Cheng Li and Santu Rana and Dinh Phung and Svetha Venkatesh},
  title = {Hierarchical Bayesian nonparametric models for knowledge discovery from electronic medical records },
  journal = {Knowledge-Based Systems },
  year = {2016},
  volume = {99},
  pages = {168 - 182},
  url = {http://www.sciencedirect.com/science/article/pii/S0950705116000836},
  doi = {10.1016/j.knosys.2016.02.005}
}
</pre></td>
</tr>
<tr id="cheng2016Toxicity" class="entry">
	<td>Li C, Gupta S, Rana S, Luo W, Venkatesh S, Ashely D and Phung D (2016), <i>"Toxicity Prediction in Cancer Using Multiple Instance Learning in a Multi-task Framework"</i>, In Pacific-Asia Conference on Knowledge Discovery and Data Mining. , pp. 152-164. Springer International Publishing.
	<p class="infolinks">[<a href="javascript:toggleInfo('cheng2016Toxicity','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('cheng2016Toxicity','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1007/978-3-319-31753-3_13" target="_blank">DOI</a>] [<a href="http://dx.doi.org/10.1007/978-3-319-31753-3_13" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_cheng2016Toxicity" class="abstract noshow">
	<td><b>Abstract</b>: Treatments of cancer cause severe side effects called toxicities. Reduction of such effects is crucial in cancer care. To impact care, we need to predict toxicities at fortnightly intervals. This toxicity data differs from traditional time series data as toxicities can be caused by one treatment on a given day alone, and thus it is necessary to consider the effect of the singular data vector causing toxicity. We model the data before prediction points using the multiple instance learning, where each bag is composed of multiple instances associated with daily treatments and patient-specific attributes, such as chemotherapy, radiotherapy, age and cancer types. We then formulate a Bayesian multi-task framework to enhance toxicity prediction at each prediction point. The use of the prior allows factors to be shared across task predictors. Our proposed method simultaneously captures the heterogeneity of daily treatments and performs toxicity prediction at different prediction points. Our method was evaluated on a real-word dataset of more than 2000 cancer patients and had achieved a better prediction accuracy in terms of AUC than the state-of-art baselines.</td>
</tr>
<tr id="bib_cheng2016Toxicity" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{cheng2016Toxicity,
  author = {Li, Cheng and Gupta, Sunil and Rana, Santu and Luo, Wei and Venkatesh, Svetha and Ashely, David and Phung, Dinh},
  editor = {Bailey, James and Khan, Latifur and Washio, Takashi and Dobbie, Gill and Huang, Zhexue Joshua and Wang, Ruili},
  title = {Toxicity Prediction in Cancer Using Multiple Instance Learning in a Multi-task Framework},
  booktitle = {Pacific-Asia Conference on Knowledge Discovery and Data Mining},
  publisher = {Springer International Publishing},
  year = {2016},
  pages = {152--164},
  url = {http://dx.doi.org/10.1007/978-3-319-31753-3_13},
  doi = {10.1007/978-3-319-31753-3_13}
}
</pre></td>
</tr>
<tr id="dang2016exceptional" class="entry">
	<td>Nguyen D, Luo W, Phung D and Venkatesh S (2016), <i>"Exceptional Contrast Set Mining: Moving beyond the deluge of the obvious"</i>, In Proceedings of the 29th Australasian Joint Conference on Artificial Intelligence (AI 2016), Hobart, Australia, December,. , pp. 455-468.
	<p class="infolinks"> [<a href="javascript:toggleInfo('dang2016exceptional','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_dang2016exceptional" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{dang2016exceptional,
  author = {Nguyen, Dang and Luo, Wei and Phung, Dinh and Venkatesh, Svetha},
  title = {Exceptional Contrast Set Mining: Moving beyond the deluge of the obvious},
  booktitle = {Proceedings of the 29th Australasian Joint Conference on Artificial Intelligence (AI 2016), Hobart, Australia, December,},
  year = {2016},
  pages = {455--468}
}
</pre></td>
</tr>
<tr id="Dao_etal_16Discovering" class="entry">
	<td>Dao B, Nguyen T, Venkatesh S and Phung D (2016), <i>"Discovering Latent Affective Dynamics among Individuals in Online Mental Health-related Communities"</i>, In Proceedings of the IEEE International Conference on Multimedia and Expo (ICME). , pp. 1-6.
	<p class="infolinks">[<a href="javascript:toggleInfo('Dao_etal_16Discovering','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Dao_etal_16Discovering','bibtex')">BibTeX</a>] [<a href="http://prada-research.net/~thin/uploads/Main/Dao_etal_16Discovering.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Dao_etal_16Discovering" class="abstract noshow">
	<td><b>Abstract</b>: The discovery of latent affective patterns of individuals with affective disorders will potentially enhance the diagnosis and treatment of mental disorders. This paper studies the phenomena of affective transitions among individuals in online mental health communities. We apply non-negative matrix factorization model to extract the common and individual factors of affective transitions across groups of individuals in different levels of affective disorders. We examine the latent patterns of emotional transitions and investigate the effects of emotional transitions across the cohorts. We establish a novel framework of utilizing social media as sensors of mood and emotional transitions. This work might suggest the base of new systems to screen individuals and communities at high risks of mental health problems in online settings.</td>
</tr>
<tr id="bib_Dao_etal_16Discovering" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{Dao_etal_16Discovering,
  author = {Bo Dao and Thin Nguyen and Svetha Venkatesh and Dinh Phung},
  title = {Discovering Latent Affective Dynamics among Individuals in Online Mental Health-related Communities},
  booktitle = {Proceedings of the IEEE International Conference on Multimedia and Expo (ICME)},
  year = {2016},
  pages = {1--6},
  url = {http://prada-research.net/&nbsp;thin/uploads/Main/Dao_etal_16Discovering.pdf}
}
</pre></td>
</tr>
<tr id="do2016outlier" class="entry">
	<td>Do K, Tran T, Phung D and Venkatesh S (2016), <i>"Outlier Detection on Mixed-Type Data: An Energy-based Approach"</i>, In International Conference on Advanced Data Mining and Applications (ADMA 2016). , pp. 111-125.
	<p class="infolinks"> [<a href="javascript:toggleInfo('do2016outlier','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_do2016outlier" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{do2016outlier,
  author = {Do, K. and Tran, Truyen. and Phung, Dinh. and Venkatesh, Svetha.},
  title = {Outlier Detection on Mixed-Type Data: An Energy-based Approach},
  booktitle = {International Conference on Advanced Data Mining and Applications (ADMA 2016)},
  year = {2016},
  pages = {111--125}
}
</pre></td>
</tr>
<tr id="gopakumar2016stabilizing" class="entry">
	<td>Gopakumar S, Tran T, Phung D and Venkatesh S (2016), <i>"Stabilizing Linear Prediction Models using Autoencoder"</i>, In 12th International Conference on Advanced Data Mining and Applications (ADMA). , pp. 651-663.
	<p class="infolinks"> [<a href="javascript:toggleInfo('gopakumar2016stabilizing','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_gopakumar2016stabilizing" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{gopakumar2016stabilizing,
  author = {Gopakumar, S. and Tran, T. and Phung, D. and Venkatesh,S.},
  title = {Stabilizing Linear Prediction Models using Autoencoder},
  booktitle = {12th International Conference on Advanced Data Mining and Applications (ADMA)},
  year = {2016},
  pages = {651--663}
}
</pre></td>
</tr>
<tr id="greenhill2008Virtual" class="entry">
	<td>Greenhill S and Venkatesh S (2016), <i>"Virtual observer"</i> (US9420234B2, EP2005748)
	<p class="infolinks"> [<a href="javascript:toggleInfo('greenhill2008Virtual','bibtex')">BibTeX</a>] [<a href="https://patents.google.com/patent/US9420234B2/en" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="bib_greenhill2008Virtual" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@patent{greenhill2008Virtual,
  author = {Greenhill, S. and Venkatesh, S.},
  title = {Virtual observer},
  year = {2016},
  number = {US9420234B2, EP2005748},
  url = {https://patents.google.com/patent/US9420234B2/en}
}
</pre></td>
</tr>
<tr id="gupta2014modelling" class="entry">
	<td>Gupta S, Phung D and Venkatesh S (2016), <i>"Modelling multilevel data in multimedia: A hierarchical factor analysis approach"</i>, Multimedia Tools and Applications.  Vol. 75(9), pp. 4933-4955. Springer.
	<p class="infolinks"> [<a href="javascript:toggleInfo('gupta2014modelling','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_gupta2014modelling" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{gupta2014modelling,
  author = {Gupta, Sunil and Phung, Dinh and Venkatesh, Svetha},
  title = {Modelling multilevel data in multimedia: A hierarchical factor analysis approach},
  journal = {Multimedia Tools and Applications},
  publisher = {Springer},
  year = {2016},
  volume = {75},
  number = {9},
  pages = {4933--4955}
}
</pre></td>
</tr>
<tr id="Gupta2016Differentially" class="entry">
	<td>Gupta S, Rana S and Venkatesh S (2016), <i>"Differentially Private Multi-task Learning"</i>, In Intelligence and Security Informatics: 11th Pacific Asia Workshop. PAISI 2016, Auckland, New Zealand, April 19, 2016, Proceedings. , pp. 101-113. Springer International Publishing.
	<p class="infolinks">[<a href="javascript:toggleInfo('Gupta2016Differentially','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Gupta2016Differentially','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1007/978-3-319-31863-9_8" target="_blank">DOI</a>] [<a href="http://dx.doi.org/10.1007/978-3-319-31863-9_8" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Gupta2016Differentially" class="abstract noshow">
	<td><b>Abstract</b>: Privacy restrictions of sensitive data repositories imply that the data analysis is performed in isolation at each data source. A prime example is the isolated nature of building prognosis models from hospital data and the associated challenge of dealing with small number of samples in risk classes (e.g. suicide) while doing so. Pooling knowledge from other hospitals, through multi-task learning, can alleviate this problem. However, if knowledge is to be shared unrestricted, privacy is breached. Addressing this, we propose a novel multi-task learning method that preserves privacy of data under the strong guarantees of differential privacy. Further, we develop a novel attribute-wise noise addition scheme that significantly lifts the utility of the proposed method. We demonstrate the effectiveness of our method with a synthetic and two real datasets.</td>
</tr>
<tr id="bib_Gupta2016Differentially" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{Gupta2016Differentially,
  author = {Gupta, Sunil and Rana, Santu and Venkatesh, Svetha},
  editor = {Chau, Michael and Wang, Alan G. and Chen, Hsinchun},
  title = {Differentially Private Multi-task Learning},
  booktitle = {Intelligence and Security Informatics: 11th Pacific Asia Workshop. PAISI 2016, Auckland, New Zealand, April 19, 2016, Proceedings},
  publisher = {Springer International Publishing},
  year = {2016},
  pages = {101--113},
  url = {http://dx.doi.org/10.1007/978-3-319-31863-9_8},
  doi = {10.1007/978-3-319-31863-9_8}
}
</pre></td>
</tr>
<tr id="Gupta2016newtransfer" class="entry">
	<td>Gupta S, Rana S, Saha B, Phung D and Venkatesh S (2016), <i>"A new transfer learning framework with application to model-agnostic multi-task learning"</i>, Knowledge and Information Systems.  Vol. 49(3), pp. 933-973.
	<p class="infolinks">[<a href="javascript:toggleInfo('Gupta2016newtransfer','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Gupta2016newtransfer','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1007/s10115-016-0926-z" target="_blank">DOI</a>] [<a href="http://dx.doi.org/10.1007/s10115-016-0926-z" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Gupta2016newtransfer" class="abstract noshow">
	<td><b>Abstract</b>: Learning from small number of examples is a challenging problem in machine learning. An effective way to improve the performance is through exploiting knowledge from other related tasks. Multi-task learning (MTL) is one such useful paradigm that aims to improve the performance through jointly modeling multiple related tasks. Although there exist numerous classification or regression models in machine learning literature, most of the MTL models are built around ridge or logistic regression. There exist some limited works, which propose multi-task extension of techniques such as support vector machine, Gaussian processes. However, all these MTL models are tied to specific classification or regression algorithms and there is no single MTL algorithm that can be used at a meta level for any given learning algorithm. Addressing this problem, we propose a generic, model-agnostic joint modeling framework that can take any classification or regression algorithm of a practitioner's choice (standard or custom-built) and build its MTL variant. The key observation that drives our framework is that due to small number of examples, the estimates of task parameters are usually poor, and we show that this leads to an under-estimation of task relatedness between any two tasks with high probability. We derive an algorithm that brings the tasks closer to their true relatedness by improving the estimates of task parameters. This is achieved by appropriate sharing of data across tasks. We provide the detail theoretical underpinning of the algorithm. Through our experiments with both synthetic and real datasets, we demonstrate that the multi-task variants of several classifiers/regressors (logistic regression, support vector machine, K-nearest neighbor, Random Forest, ridge regression, support vector regression) convincingly outperform their single-task counterparts. We also show that the proposed model performs comparable or better than many state-of-the-art MTL and transfer learning baselines.</td>
</tr>
<tr id="bib_Gupta2016newtransfer" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{Gupta2016newtransfer,
  author = {Gupta, Sunil and Rana, Santu and Saha, Budhaditya and Phung, Dinh and Venkatesh, Svetha},
  title = {A new transfer learning framework with application to model-agnostic multi-task learning},
  journal = {Knowledge and Information Systems},
  year = {2016},
  volume = {49},
  number = {3},
  pages = {933--973},
  url = {http://dx.doi.org/10.1007/s10115-016-0926-z},
  doi = {10.1007/s10115-016-0926-z}
}
</pre></td>
</tr>
<tr id="harikumar2016extracting" class="entry">
	<td>Harikumar H, Nguyen T, Rana S, Gupta S, Kaimal R and Venkatesh S (2016), <i>"Extracting Key Challenges in Achieving Sobriety through Shared Subspace Learning"</i>, In 12th International Conference on Advanced Data Mining and Applications (ADMA). , pp. 420-433.
	<p class="infolinks"> [<a href="javascript:toggleInfo('harikumar2016extracting','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_harikumar2016extracting" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{harikumar2016extracting,
  author = {Harikumar, H. and Nguyen, T. and Rana, S. and Gupta, S. and Kaimal, R. and Venkatesh, S.},
  title = {Extracting Key Challenges in Achieving Sobriety through Shared Subspace Learning},
  booktitle = {12th International Conference on Advanced Data Mining and Applications (ADMA)},
  year = {2016},
  pages = {420--433}
}
</pre></td>
</tr>
<tr id="harikumar2016understanding" class="entry">
	<td>Harikumar H, Nguyen T, Rana S, Gupta S, Kaimal R and Venkatesh S (2016), <i>"Understanding Behavioral Differences between Short and Long-term Drinking Abstainers from Social Media"</i>, In 12th International Conference on Advanced Data Mining and Applications (ADMA). , pp. 520-533.
	<p class="infolinks"> [<a href="javascript:toggleInfo('harikumar2016understanding','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_harikumar2016understanding" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{harikumar2016understanding,
  author = {Harikumar, H. and Nguyen, T. and Rana, S. and Gupta, S. and Kaimal, R. and Venkatesh, S.},
  title = {Understanding Behavioral Differences between Short and Long-term Drinking Abstainers from Social Media},
  booktitle = {12th International Conference on Advanced Data Mining and Applications (ADMA)},
  year = {2016},
  pages = {520--533}
}
</pre></td>
</tr>
<tr id="huynh_phung_venkatesh_nguyen_hoffman_bui_uai16scalable" class="entry">
	<td>Huynh V, Phung DQ, Venkatesh S, Nguyen X, Hoffman MD and Bui HH (2016), <i>"Scalable Nonparametric Bayesian Multilevel Clustering"</i>, In The 32th Conference on Uncertainty in Artificial Intelligence., June, 2016. , pp. 289-298.
	<p class="infolinks"> [<a href="javascript:toggleInfo('huynh_phung_venkatesh_nguyen_hoffman_bui_uai16scalable','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_huynh_phung_venkatesh_nguyen_hoffman_bui_uai16scalable" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{huynh_phung_venkatesh_nguyen_hoffman_bui_uai16scalable,
  author = {Huynh, Viet and Phung, Dinh Q and Venkatesh, Svetha and Nguyen, XuanLong and Hoffman, Matthew D and Bui, Hung Hai},
  title = {Scalable Nonparametric Bayesian Multilevel Clustering},
  booktitle = {The 32th Conference on Uncertainty in Artificial Intelligence},
  year = {2016},
  pages = {289--298}
}
</pre></td>
</tr>
<tr id="Joy2016Flexible" class="entry">
	<td>Joy TT, Rana S, Gupta S and Venkatesh S (2016), <i>"Flexible Transfer Learning Framework for Bayesian Optimisation"</i>, In Advances in Knowledge Discovery and Data Mining: 20th Pacific-Asia Conference, PAKDD 2016, Auckland, New Zealand, April 19-22, 2016, Proceedings, Part I. , pp. 102-114. Springer International Publishing.
	<p class="infolinks">[<a href="javascript:toggleInfo('Joy2016Flexible','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Joy2016Flexible','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1007/978-3-319-31753-3_9" target="_blank">DOI</a>] [<a href="http://dx.doi.org/10.1007/978-3-319-31753-3_9" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Joy2016Flexible" class="abstract noshow">
	<td><b>Abstract</b>: Bayesian optimisation is an efficient technique to optimise functions that are expensive to compute. In this paper, we propose a novel framework to transfer knowledge from a completed source optimisation task to a new target task in order to overcome the cold start problem. We model source data as noisy observations of the target function. The level of noise is computed from the data in a Bayesian setting. This enables flexible knowledge transfer across tasks with differing relatedness, addressing a limitation of the existing methods. We evaluate on the task of tuning hyperparameters of two machine learning algorithms. Treating a fraction of the whole training data as source and the whole as the target task, we show that our method finds the best hyperparameters in the least amount of time compared to both the state-of-art and no transfer method.</td>
</tr>
<tr id="bib_Joy2016Flexible" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{Joy2016Flexible,
  author = {Joy, Tinu Theckel and Rana, Santu and Gupta, Sunil and Venkatesh, Svetha},
  editor = {Bailey, James and Khan, Latifur and Washio, Takashi and Dobbie, Gill and Huang, Zhexue Joshua and Wang, Ruili},
  title = {Flexible Transfer Learning Framework for Bayesian Optimisation},
  booktitle = {Advances in Knowledge Discovery and Data Mining: 20th Pacific-Asia Conference, PAKDD 2016, Auckland, New Zealand, April 19-22, 2016, Proceedings, Part I},
  publisher = {Springer International Publishing},
  year = {2016},
  pages = {102--114},
  url = {http://dx.doi.org/10.1007/978-3-319-31753-3_9},
  doi = {10.1007/978-3-319-31753-3_9}
}
</pre></td>
</tr>
<tr id="joy2016hyperparameter" class="entry">
	<td>Joy TT, Rana S, Gupta S and Venkatesh S (2016), <i>"Hyperparameter tuning for big data using Bayesian optimisation"</i>, In 23rd International Conference on Pattern Recognition (ICPR). , pp. 2574-2579.
	<p class="infolinks">[<a href="javascript:toggleInfo('joy2016hyperparameter','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('joy2016hyperparameter','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1109/ICPR.2016.7900023" target="_blank">DOI</a>] [<a href="http://ieeexplore.ieee.org/abstract/document/7900023/" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_joy2016hyperparameter" class="abstract noshow">
	<td><b>Abstract</b>: Hyperparameters play a crucial role in the model selection of machine learning algorithms. Tuning these hyperparameters can be exhaustive when the data is large. Bayesian optimisation has emerged as an efficient tool for hyperparameter tuning of machine learning algorithms. In this paper, we propose a novel framework for tuning the hyperparameters for big data using Bayesian optimisation. We divide the big data into chunks and generate hyperparameter configurations for the chunks using the standard Bayesian optimisation. We utilise this information from the chunks for hyperparameter tuning on big data using a transfer learning setting. We evaluate the performance of the proposed method on the task of tuning hyperparameters of two machine learning algorithms. We show that our method achieves the best available hyperparameter configuration within less computational time compared to the state-of-art hyperparameter tuning methods.</td>
</tr>
<tr id="bib_joy2016hyperparameter" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{joy2016hyperparameter,
  author = {Joy, Tinu Theckel and Rana, Santu and Gupta, Sunil and Venkatesh, Svetha},
  title = {Hyperparameter tuning for big data using Bayesian optimisation},
  booktitle = {23rd International Conference on Pattern Recognition (ICPR)},
  year = {2016},
  pages = {2574--2579},
  url = {http://ieeexplore.ieee.org/abstract/document/7900023/},
  doi = {10.1109/ICPR.2016.7900023}
}
</pre></td>
</tr>
<tr id="joy2016multiple" class="entry">
	<td>Joy TT, Rana S, Gupta S and Venkatesh S (2016), <i>"Multiple Recommendation for Bayesian optimization via Multi-Scale Search"</i>, In Proceedings of NIPS Workshop on Bayesian Optimization: Black-box Optimization and Beyond, BayesOpt 2016. , pp. 5.
	<p class="infolinks">[<a href="javascript:toggleInfo('joy2016multiple','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('joy2016multiple','bibtex')">BibTeX</a>] [<a href="https://bayesopt.github.io/papers/2016/Theckel.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_joy2016multiple" class="abstract noshow">
	<td><b>Abstract</b>: Bayesian optimization operates sequentially recommending single evaluation setting each time. Many practical applications, however, have the facility of evaluating a batch of multiple settings simultaneously. Current batch Bayesian methods are mostly heuristic based and none have considered heteroscedasticity of the unknown objective function. We base our method on extracting the most promising batch of recommendations by searching across different smoothness assumptions which is realized through different length-scales of the Gaussian process covariance function. Theoretical analysis suggests that the proposed batch method has tighter regret bound than a pure sequential approach. Further improvement is brought by introducing a novel multi-armed bandit (MAB) based length-scale selection procedure, resulting in a more computationally efficient algorithm. We evaluate our method by minimizing three heteroscedastic benchmarked test functions and tuning the hyperparameters of two machine learning algorithms.</td>
</tr>
<tr id="bib_joy2016multiple" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{joy2016multiple,
  author = {Joy, Tinu Theckel and Rana, Santu and Gupta, Sunil and Venkatesh, Svetha},
  title = {Multiple Recommendation for Bayesian optimization via Multi-Scale Search},
  booktitle = {Proceedings of NIPS Workshop on Bayesian Optimization: Black-box Optimization and Beyond, BayesOpt 2016},
  year = {2016},
  pages = {5},
  url = {https://bayesopt.github.io/papers/2016/Theckel.pdf}
}
</pre></td>
</tr>
<tr id="Kamkar2016Stabilizing" class="entry">
	<td>Kamkar I, Gupta S, Phung D and Venkatesh S (2016), <i>"Stabilizing l1-norm prediction models by supervised feature grouping"</i>, Journal of Biomedical Informatics.  Vol. 59, pp. 149 - 168.
	<p class="infolinks">[<a href="javascript:toggleInfo('Kamkar2016Stabilizing','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Kamkar2016Stabilizing','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1016/j.jbi.2015.11.012" target="_blank">DOI</a>] [<a href="http://www.sciencedirect.com/science/article/pii/S1532046415002804" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Kamkar2016Stabilizing" class="abstract noshow">
	<td><b>Abstract</b>: Abstract Emerging Electronic Medical Records (EMRs) have reformed the modern healthcare. These records have great potential to be used for building clinical prediction models. However, a problem in using them is their high dimensionality. Since a lot of information may not be relevant for prediction, the underlying complexity of the prediction models may not be high. A popular way to deal with this problem is to employ feature selection. Lasso and l 1 -norm based feature selection methods have shown promising results. But, in presence of correlated features, these methods select features that change considerably with small changes in data. This prevents clinicians to obtain a stable feature set, which is crucial for clinical decision making. Grouping correlated variables together can improve the stability of feature selection, however, such grouping is usually not known and needs to be estimated for optimal performance. Addressing this problem, we propose a new model that can simultaneously learn the grouping of correlated features and perform stable feature selection. We formulate the model as a constrained optimization problem and provide an efficient solution with guaranteed convergence. Our experiments with both synthetic and real-world datasets show that the proposed model is significantly more stable than Lasso and many existing state-of-the-art shrinkage and classification methods. We further show that in terms of prediction performance, the proposed method consistently outperforms Lasso and other baselines. Our model can be used for selecting stable risk factors for a variety of healthcare problems, so it can assist clinicians toward accurate decision making. </td>
</tr>
<tr id="bib_Kamkar2016Stabilizing" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{Kamkar2016Stabilizing,
  author = {Iman Kamkar and Sunil Gupta and Dinh Phung and Svetha Venkatesh},
  title = {Stabilizing l1-norm prediction models by supervised feature grouping},
  journal = {Journal of Biomedical Informatics},
  year = {2016},
  volume = {59},
  pages = {149 - 168},
  url = {http://www.sciencedirect.com/science/article/pii/S1532046415002804},
  doi = {10.1016/j.jbi.2015.11.012}
}
</pre></td>
</tr>
<tr id="kamkar2016stable" class="entry">
	<td>Kamkar I, Gupta S, Li C, Phung D and Venkatesh S (2016), <i>"Stable Clinical Prediction using Graph Support Vector Machines"</i>, In 23rd International Conference on Pattern Recognition (ICPR 2016). , pp. 3332-3337.
	<p class="infolinks"> [<a href="javascript:toggleInfo('kamkar2016stable','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_kamkar2016stable" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{kamkar2016stable,
  author = {Kamkar, Iman and Gupta, Sunil and Li, Cheng and Phung, Dinh and Venkatesh, Svetha},
  title = {Stable Clinical Prediction using Graph Support Vector Machines},
  booktitle = {23rd International Conference on Pattern Recognition (ICPR 2016)},
  year = {2016},
  pages = {3332--3337}
}
</pre></td>
</tr>
<tr id="Li_etal_16multiple" class="entry">
	<td>Li C, Gupta S, Rana S, Nguyen V and Venkatesh S (2016), <i>"Multiple Adverse Effects Prediction in Longitudinal Cancer Treatment"</i>, In Proceedings of the 23rd International Conference on Pattern Recognition. Cancun, Mexico , pp. 3156-3161.
	<p class="infolinks"> [<a href="javascript:toggleInfo('Li_etal_16multiple','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_Li_etal_16multiple" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{Li_etal_16multiple,
  author = {Li, C. and Gupta, S. and Rana, S. and Nguyen, V. and Venkatesh, S.},
  title = {Multiple Adverse Effects Prediction in Longitudinal Cancer Treatment},
  booktitle = {Proceedings of the 23rd International Conference on Pattern Recognition},
  year = {2016},
  pages = {3156--3161}
}
</pre></td>
</tr>
<tr id="li2016high" class="entry">
	<td>Li C, Rana S, Gupta S, Nguyen V and Venkatesh S (2016), <i>"High Dimensional Bayesian Optimization with Elastic Gaussian Process"</i>, In Proceedings of NIPS Workshop on Bayesian Optimization: Black-box Optimization and Beyond, BayesOpt 2016. , pp. 2883-2891.
	<p class="infolinks">[<a href="javascript:toggleInfo('li2016high','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('li2016high','bibtex')">BibTeX</a>] [<a href="https://bayesopt.github.io/papers/2016/Li.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_li2016high" class="abstract noshow">
	<td><b>Abstract</b>: Bayesian optimization depends on solving a global optimization of a acquisition function. However, the acquisition function can be extremely sharp at high dimension - having only a few peaks marooned in a large terrain of almost flat surface. Global optimization algorithms such as DIRECT are infeasible at higher dimensions and gradient-dependent methods cannot move if initialized in the flat terrain. We propose an algorithm that enables local gradient-dependent algorithms to move through the flat terrain by using a sequence of gross-to-finer Gaussian process priors on the objective function. Experiments clearly demonstrate the utility of the proposed method at high dimension using synthetic and real-world case studies.</td>
</tr>
<tr id="bib_li2016high" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{li2016high,
  author = {Li, Cheng and Rana, Santu and Gupta, Sunil and Nguyen, Vu and Venkatesh, Svetha},
  title = {High Dimensional Bayesian Optimization with Elastic Gaussian Process},
  booktitle = {Proceedings of NIPS Workshop on Bayesian Optimization: Black-box Optimization and Beyond, BayesOpt 2016},
  year = {2016},
  pages = {2883--2891},
  url = {https://bayesopt.github.io/papers/2016/Li.pdf}
}
</pre></td>
</tr>
<tr id="luo2016consistency" class="entry">
	<td>Luo W, Harvey R, Tran T, Phung D, Venkatesh S and Connor JP (2016), <i>"Consistency of the Health of the Nation Outcome Scales (HoNOS) at inpatient-to-community transition"</i>, BMJ open.  Vol. 6(4), pp. e010732. British Medical Journal Publishing Group.
	<p class="infolinks">[<a href="javascript:toggleInfo('luo2016consistency','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('luo2016consistency','bibtex')">BibTeX</a>] [<a href="http://bmjopen.bmj.com/content/6/4/e010732.abstract" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_luo2016consistency" class="abstract noshow">
	<td><b>Abstract</b>: Objectives: The Health of the Nation Outcome Scales (HoNOS) are mandated outcome-measures in many mental-health jurisdictions. When HoNOS are used in different care settings, it is important to assess if setting specific bias exists. This article examines the consistency of HoNOS in a sample of psychiatric patients transitioned from acute inpatient care and community centres.<br>Setting: A regional mental health service with both acute and community facilities.<br>Participants: 111 psychiatric patients were transferred from inpatient care to community care from 2012 to 2014. Their HoNOS scores were extracted from a clinical database; Each inpatient-discharge assessment was followed by a community-intake assessment, with the median period between assessments being 4 days (range 0-14). Assessor experience and professional background were recorded.<br>Primary and secondary outcome measures: The difference of HoNOS at inpatient-discharge and community-intake were assessed with Pearson correlation, Cohen's K and effect size.<br>Results: Inpatient-discharge HoNOS was on average lower than community-intake HoNOS. The average HoNOS was 8.05 at discharge (median 7, range 1-22), and 12.16 at intake (median 12, range 1-25), an average increase of 4.11 (SD 6.97). Pearson correlation between two total scores was 0.073 (95% CI -0.095 to 0.238) and Cohen's K was 0.02 (95% CI -0.02 to 0.06). Differences did not appear to depend on assessor experience or professional background.<br>Conclusions: Systematic change in the HoNOS occurs at inpatient-to-community transition. Some caution should be exercised in making direct comparisons between inpatient HoNOS and community HoNOS scores.</td>
</tr>
<tr id="bib_luo2016consistency" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{luo2016consistency,
  author = {Luo, Wei and Harvey, Richard and Tran, Truyen and Phung, Dinh and Venkatesh, Svetha and Connor, Jason P},
  title = {Consistency of the Health of the Nation Outcome Scales (HoNOS) at inpatient-to-community transition},
  journal = {BMJ open},
  publisher = {British Medical Journal Publishing Group},
  year = {2016},
  volume = {6},
  number = {4},
  pages = {e010732},
  url = {http://bmjopen.bmj.com/content/6/4/e010732.abstract}
}
</pre></td>
</tr>
<tr id="luo2016guidelines" class="entry">
	<td>Luo W, Phung D, Tran T, Gupta S, Rana S, Karmakar C, Shilton A, Yearwood J, Dimitrova N, Ho TB and others (2016), <i>"Guidelines for developing and reporting machine learning predictive models in biomedical research: a multidisciplinary view"</i>, Journal of medical Internet research.  Vol. 18(12), pp. e323. JMIR Publications Inc., Toronto, Canada.
	<p class="infolinks"> [<a href="javascript:toggleInfo('luo2016guidelines','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_luo2016guidelines" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{luo2016guidelines,
  author = {Luo, Wei and Phung, Dinh and Tran, Truyen and Gupta, Sunil and Rana, Santu and Karmakar, Chandan and Shilton, Alistair and Yearwood, John and Dimitrova, Nevenka and Ho, Tu Bao and others},
  title = {Guidelines for developing and reporting machine learning predictive models in biomedical research: a multidisciplinary view},
  journal = {Journal of medical Internet research},
  publisher = {JMIR Publications Inc., Toronto, Canada},
  year = {2016},
  volume = {18},
  number = {12},
  pages = {e323}
}
</pre></td>
</tr>
<tr id="luo2016screening" class="entry">
	<td>Luo W, Huning EY, Tran T, Phung D and Venkatesh S (2016), <i>"Screening for post 32-week preterm birth risk: how helpful is routine perinatal data collection?"</i>, Heliyon.  Vol. 2(6), pp. e00119.
	<p class="infolinks">[<a href="javascript:toggleInfo('luo2016screening','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('luo2016screening','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1016/j.heliyon.2016.e00119" target="_blank">DOI</a>] [<a href="http://www.heliyon.com/article/e00119/" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_luo2016screening" class="abstract noshow">
	<td><b>Abstract</b>: Preterm birth is a clinical event significant but difficult to predict. Biomarkers such as fetal fibronectin and cervical length are effective, but the often are used only for women with clinically suspected preterm risk. It is unknown whether routinely collected data can be used in early pregnancy to stratify preterm birth risk by identifying asymptomatic women. This paper tries to determine the value of the Victorian Perinatal Data Collection (VPDC) dataset in predicting preterm birth and screening for invasive tests.</td>
</tr>
<tr id="bib_luo2016screening" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{luo2016screening,
  author = {Luo, Wei and Huning, Emily YS and Tran, Truyen and Phung, Dinh and Venkatesh, Svetha},
  title = {Screening for post 32-week preterm birth risk: how helpful is routine perinatal data collection?},
  journal = {Heliyon},
  year = {2016},
  volume = {2},
  number = {6},
  pages = {e00119},
  url = {http://www.heliyon.com/article/e00119/},
  doi = {10.1016/j.heliyon.2016.e00119}
}
</pre></td>
</tr>
<tr id="Nguyen_etal_16Discriminative" class="entry">
	<td>Nguyen T, Borland R, Yearwood J, Yong H, Venkatesh S and Phung D (2016), <i>"Discriminative cues for different stages of smoking cessation in online community"</i>, In Proceedings of the International Conference on Web Information Systems Engineering (WISE). , pp. 146-153. Springer International Publishing.
	<p class="infolinks">[<a href="javascript:toggleInfo('Nguyen_etal_16Discriminative','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Nguyen_etal_16Discriminative','bibtex')">BibTeX</a>] [<a href="http://prada-research.net/~thin/uploads/Main/Nguyen_etal_16Discriminative.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Nguyen_etal_16Discriminative" class="abstract noshow">
	<td><b>Abstract</b>: Smoking is one of the leading causes of preventable death, being responsible for about six million deaths annually worldwide. Most smokers want to quit, but many find quitting difficult. The Internet enables people interested in quitting smoking to connect with others via online communities; however, the characteristics of these discussions are not well understood. This work aims to explore the textual cues of an online community interested in quitting smoking. A total of approximately 5,000 posts were randomly selected from the community. Four subgroups of posts based on the cessation days of abstainers were defined: S0: within the first week, S1: within the first month (excluding cohort S0), S2: from second month to one year, and S3: beyond one year. Psycho-linguistic features and content topics were extracted from the posts and analysed. Machine learning techniques were used to discriminate the online conversations in the first week S0 from the other subgroups. Topics and psycho-linguistic features were found to be highly valid predictors of the subgroups, possibly providing an important step in understanding social media and its use in studies of smoking and other addictions in online settings.</td>
</tr>
<tr id="bib_Nguyen_etal_16Discriminative" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{Nguyen_etal_16Discriminative,
  author = {Thin Nguyen and Ron Borland and John Yearwood and Hua Yong and Svetha Venkatesh and Dinh Phung},
  title = {Discriminative cues for different stages of smoking cessation in online community},
  booktitle = {Proceedings of the International Conference on Web Information Systems Engineering (WISE)},
  publisher = {Springer International Publishing},
  year = {2016},
  pages = {146--153},
  url = {http://prada-research.net/&nbsp;thin/uploads/Main/Nguyen_etal_16Discriminative.pdf}
}
</pre></td>
</tr>
<tr id="Nguyen_etal_16LargeScale" class="entry">
	<td>Nguyen T, Venkatesh S and Phung D (2016), <i>"Large-scale stylistic analysis of formality in academia and social media"</i>, In Proceedings of the International Conference on Web Information Systems Engineering (WISE). , pp. 137-145. Springer International Publishing.
	<p class="infolinks">[<a href="javascript:toggleInfo('Nguyen_etal_16LargeScale','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Nguyen_etal_16LargeScale','bibtex')">BibTeX</a>] [<a href="http://prada-research.net/~thin/uploads/Main/Nguyen_etal_16LargeScale.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Nguyen_etal_16LargeScale" class="abstract noshow">
	<td><b>Abstract</b>: The dictum `publish or perish' has influenced the way scientists present research results as to get published, including exaggeration and overstatement of research findings. This behavior emerges patterns of using language in academia. For example, recently it has been found that the proportion of positive words has risen in the content of scientific articles over the last 40 years, which probably shows the tendency in scientists to exaggerate and overstate their research results. The practice may deviate from impersonal and formal style of academic writing. In this study the degree of formality in scientific articles is investigated through a corpus of 14 million PubMed abstracts. Three aspects of stylistic features are explored: expressing emotional information, using first person pronouns to refer to the authors, and mixing English varieties. Trends of these stylistic features in scientific publications for the last four decades were discovered. A comparison on the emotional information with other online user-generated media, including online encyclopedias, web-logs, forums, and micro-blogs, was conducted. Advances in cluster computing are employed to process large scale data, with 5.8 terabytes and 3.6 billions of data points from all the media. The results suggest the potential of pattern recognition in data at scale.</td>
</tr>
<tr id="bib_Nguyen_etal_16LargeScale" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{Nguyen_etal_16LargeScale,
  author = {Thin Nguyen and Svetha Venkatesh and Dinh Phung},
  title = {Large-scale stylistic analysis of formality in academia and social media},
  booktitle = {Proceedings of the International Conference on Web Information Systems Engineering (WISE)},
  publisher = {Springer International Publishing},
  year = {2016},
  pages = {137--145},
  url = {http://prada-research.net/&nbsp;thin/uploads/Main/Nguyen_etal_16LargeScale.pdf}
}
</pre></td>
</tr>
<tr id="nguyen_nguyen_venkatesh_phung_icpr16mcnc" class="entry">
	<td>Nguyen T-B, Nguyen V, Venkatesh S and Phung D (2016), <i>"MCNC: Multi-channel Nonparametric Clustering from Heterogeneous Data"</i>, In 23rd International Conference on Pattern Recognition (ICPR 2016). , pp. 3633-3638.
	<p class="infolinks">[<a href="javascript:toggleInfo('nguyen_nguyen_venkatesh_phung_icpr16mcnc','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('nguyen_nguyen_venkatesh_phung_icpr16mcnc','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="abs_nguyen_nguyen_venkatesh_phung_icpr16mcnc" class="abstract noshow">
	<td><b>Abstract</b>: Bayesian nonparametric (BNP) models have recently become popular due to its flexibility in identifying the unknown number of clusters. However, they have difficulties handling heterogeneous data from multiple sources. Existing BNP works either treat each of these sources independently -- hence do not benefit from the correlating information between them, or require to specify data sources as primary or context channels. In this paper, we present a BNP framework, termed MCNC, which has the ability to (1) discover co-patterns from multiple sources; (2) explore multi-channel data simultaneously and equally; (3) automatically identify a suitable number of patterns from data; and (4) handle missing data. The key idea is to tweak the base measure of a BNP model being a product-space. We demonstrate our framework on synthetic and real-world datasets to discover the identity--location--time (a.k.a who--where--when) patterns in two settings of complete and missing data. The experimenal results highlight the effectiveness of our MCNC in both cases of complete and missing data.</td>
</tr>
<tr id="bib_nguyen_nguyen_venkatesh_phung_icpr16mcnc" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{nguyen_nguyen_venkatesh_phung_icpr16mcnc,
  author = {Nguyen, Thanh-Binh and Nguyen, Vu and Venkatesh, Svetha and Phung, Dinh},
  title = {MCNC: Multi-channel Nonparametric Clustering from Heterogeneous Data},
  booktitle = {23rd International Conference on Pattern Recognition (ICPR 2016)},
  year = {2016},
  pages = {3633--3638}
}
</pre></td>
</tr>
<tr id="nguyen2016bayesian" class="entry">
	<td>Nguyen V, Gupta S, Rana S, Li C and Venkatesh S (2016), <i>"A Bayesian Nonparametric Approach for Multi-label Classification"</i>, In Proceedings of The 8th Asian Conference on Machine Learning. , pp. 254-269.
	<p class="infolinks">[<a href="javascript:toggleInfo('nguyen2016bayesian','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('nguyen2016bayesian','bibtex')">BibTeX</a>] [<a href="http://www.jmlr.org/proceedings/papers/v63/nguyen93.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_nguyen2016bayesian" class="abstract noshow">
	<td><b>Abstract</b>: Many real-world applications require multi-label classification where multiple target labels are assigned to each instance. In multi-label classification, there exist the intrinsic correlations between the labels and features. These correlations are beneficial for multi-label classification task since they reflect the coexistence of the input and output spaces that can be exploited for prediction. Traditional classification methods have attempted to reveal these correlations in different ways. However, existing methods demand expensive computation complexity for finding such correlation structures. Furthermore, these approaches can not identify the suitable number of label-feature correlation patterns. In this paper, we propose a Bayesian nonparametric (BNP) framework for multi-label classification that can automatically learn and exploit the unknown number of multi-label correlation. We utilize the recent techniques in stochastic inference to derive the cheap (but efficient) posterior inference algorithm for the model. In addition, our model can naturally exploit the useful information from missing label samples. Furthermore, we extend the model to update parameters in an online fashion that highlights the flexibility of our model against the existing approaches. We compare our method with the state-of-the-art multi-label classification algorithms on real-world datasets using both complete and missing label settings. Our model achieves better classification accuracy while our running time is consistently much faster than the baselines in an order of magnitude.</td>
</tr>
<tr id="bib_nguyen2016bayesian" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{nguyen2016bayesian,
  author = {Nguyen, Vu and Gupta, Sunil and Rana, Santu and Li, Cheng and Venkatesh, Svetha},
  title = {A Bayesian Nonparametric Approach for Multi-label Classification},
  booktitle = {Proceedings of The 8th Asian Conference on Machine Learning},
  year = {2016},
  pages = {254--269},
  url = {http://www.jmlr.org/proceedings/papers/v63/nguyen93.pdf}
}
</pre></td>
</tr>
<tr id="nguyen2016control" class="entry">
	<td>Nguyen D, Luo W, Phung D and Venkatesh S (2016), <i>"Control Matching via Discharge Code Sequences"</i>, In NIPS 2016 Workshop on Machine Learning for Health. , pp. 5.
	<p class="infolinks">[<a href="javascript:toggleInfo('nguyen2016control','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('nguyen2016control','bibtex')">BibTeX</a>] [<a href="https://arxiv.org/pdf/1612.01812.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_nguyen2016control" class="abstract noshow">
	<td><b>Abstract</b>: In this paper, we consider the patient similarity matching problem over a cancer cohort of more than 220,000 patients. Our approach first leverages on Word2Vec framework to embed ICD codes into vector-valued representation. We then propose a sequential algorithm for case-control matching on this representation space of diagnosis codes. The novel practice of applying the sequential matching on the vector representation lifted the matching accuracy measured through multiple clinical outcomes. We reported the results on a large-scale dataset to demonstrate the effectiveness of our method. For such a large dataset where most clinical information has been codified, the new method is particularly relevant.</td>
</tr>
<tr id="bib_nguyen2016control" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{nguyen2016control,
  author = {Nguyen, Dang and Luo, Wei and Phung, Dinh and Venkatesh, Svetha},
  title = {Control Matching via Discharge Code Sequences},
  booktitle = {NIPS 2016 Workshop on Machine Learning for Health},
  year = {2016},
  pages = {5},
  url = {https://arxiv.org/pdf/1612.01812.pdf}
}
</pre></td>
</tr>
<tr id="Nguyen2016Graphinduced" class="entry">
	<td>Nguyen TD, Tran T, Phung D and Venkatesh S (2016), <i>"Graph-induced restricted Boltzmann machines for document modeling "</i>, Information Sciences .  Vol. 328, pp. 60 - 75.
	<p class="infolinks">[<a href="javascript:toggleInfo('Nguyen2016Graphinduced','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Nguyen2016Graphinduced','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1016/j.ins.2015.08.023" target="_blank">DOI</a>] [<a href="http://www.sciencedirect.com/science/article/pii/S002002551500609X" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Nguyen2016Graphinduced" class="abstract noshow">
	<td><b>Abstract</b>: Abstract Discovering knowledge from unstructured texts is a central theme in data mining and machine learning. We focus on fast discovery of thematic structures from a corpus. Our approach is based on a versatile probabilistic formulation â€“ the restricted Boltzmann machine (RBM) â€“ where the underlying graphical model is an undirected bipartite graph. Inference is efficient â€“ document representation can be computed with a single matrix projection, making RBMs\ suitable for massive text corpora available today. Standard RBMs, however, operate on bag-of-words assumption, ignoring the inherent underlying relational structures among words. This results in less coherent word thematic grouping. We introduce graph-based regularization schemes that exploit the linguistic structures, which in turn can be constructed from either corpus statistics or domain knowledge. We demonstrate that the proposed technique improves the group coherence, facilitates visualization, provides means for estimation of intrinsic dimensionality, reduces overfitting, and possibly leads to better classification accuracy. </td>
</tr>
<tr id="bib_Nguyen2016Graphinduced" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{Nguyen2016Graphinduced,
  author = {Tu Dinh Nguyen and Truyen Tran and Dinh Phung and Svetha Venkatesh},
  title = {Graph-induced restricted Boltzmann machines for document modeling },
  journal = {Information Sciences },
  year = {2016},
  volume = {328},
  pages = {60 - 75},
  url = {http://www.sciencedirect.com/science/article/pii/S002002551500609X},
  doi = {10.1016/j.ins.2015.08.023}
}
</pre></td>
</tr>
<tr id="nguyen2016learning" class="entry">
	<td>Nguyen T-B, Nguyen V, Nguyen T, Venkatesh S, Kumar M and Phung D (2016), <i>"Learning Multifaceted Latent Activities from Heterogeneous Mobile Data"</i>, In 2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA). , pp. 389-398.
	<p class="infolinks"> [<a href="javascript:toggleInfo('nguyen2016learning','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_nguyen2016learning" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{nguyen2016learning,
  author = {Nguyen, Thanh-Binh and Nguyen, Vu and Nguyen, Thuong and Venkatesh, Svetha and Kumar, Mohan and Phung, Dinh},
  title = {Learning Multifaceted Latent Activities from Heterogeneous Mobile Data},
  booktitle = {2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)},
  year = {2016},
  pages = {389--398}
}
</pre></td>
</tr>
<tr id="Nguyen2016Nonparametric" class="entry">
	<td>Nguyen T, Gupta S, Venkatesh S and Phung D (2016), <i>"Nonparametric discovery of movement patterns from accelerometer signals "</i>, Pattern Recognition Letters .  Vol. 70, pp. 52 - 58.
	<p class="infolinks">[<a href="javascript:toggleInfo('Nguyen2016Nonparametric','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Nguyen2016Nonparametric','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1016/j.patrec.2015.11.003" target="_blank">DOI</a>] [<a href="http://www.sciencedirect.com/science/article/pii/S016786551500389X" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Nguyen2016Nonparametric" class="abstract noshow">
	<td><b>Abstract</b>: Abstract Monitoring daily physical activity plays an important role in disease prevention and intervention. This paper proposes an approach to monitor the body movement intensity levels from accelerometer data. We collect the data using the accelerometer in a realistic setting without any supervision. The ground-truth of activities is provided by the participants themselves using an experience sampling application running on their mobile phones. We compute a novel feature that has a strong correlation with the movement intensity. We use the hierarchical Dirichlet process (HDP) model to detect the activity levels from this feature. Consisting of Bayesian nonparametric priors over the parameters the model can infer the number of levels automatically. By demonstrating the approach on the publicly available USC-HAD dataset that includes ground-truth activity labels, we show a strong correlation between the discovered activity levels and the movement intensity of the activities. This correlation is further confirmed using our newly collected dataset. We further use the extracted patterns as features for clustering and classifying the activity sequences to improve performance. </td>
</tr>
<tr id="bib_Nguyen2016Nonparametric" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{Nguyen2016Nonparametric,
  author = {Thuong Nguyen and Sunil Gupta and Svetha Venkatesh and Dinh Phung},
  title = {Nonparametric discovery of movement patterns from accelerometer signals },
  journal = {Pattern Recognition Letters },
  year = {2016},
  volume = {70},
  pages = {52 - 58},
  url = {http://www.sciencedirect.com/science/article/pii/S016786551500389X},
  doi = {10.1016/j.patrec.2015.11.003}
}
</pre></td>
</tr>
<tr id="nguyen2016textual" class="entry">
	<td>Nguyen T, Venkatesh S and Phung D (2016), <i>"Textual Cues for Online Depression in Community and Personal Settings"</i>, In Advanced Data Mining and Applications: 12th International Conference, ADMA 2016, Gold Coast, QLD, Australia, December 12-15, 2016, Proceedings 12. , pp. 19-34.
	<p class="infolinks">[<a href="javascript:toggleInfo('nguyen2016textual','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('nguyen2016textual','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="abs_nguyen2016textual" class="abstract noshow">
	<td><b>Abstract</b>: Depression is often associated with poor social skills. The Internet allows individuals who are depressed to connect with others via online communities, helping them to address the social skill deficit. While the difficulty of collecting data in traditional studies raises a bar for investigating the cues of depression, the user-generated media left by depression sufferers on social media enable us to learn more about depression signs. Previous studies examined the traces left in the posts of online depression communities in comparison with other online communities. This work further investigates if the content that members of the depression community contribute to the community blogs different from what they make in their own personal blogs? The answer to this question would help to improve the performance of online depression screening for different blogging settings. The content made in the two settings were compared in three textual features: affective information, topics, and language styles. Machine learning and statistical methods were used to discriminate the blog content. All three features were found to be significantly different between depression Community and Personal blogs. Noticeably, topic and language style features, either separately or jointly used, show strong indicative power in prediction of depression blogs in personal or community settings, illustrating the potential of using content-based multi-cues for early screening of online depression communities and individuals.</td>
</tr>
<tr id="bib_nguyen2016textual" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{nguyen2016textual,
  author = {Nguyen, Thin and Venkatesh, Svetha and Phung, Dinh},
  title = {Textual Cues for Online Depression in Community and Personal Settings},
  booktitle = {Advanced Data Mining and Applications: 12th International Conference, ADMA 2016, Gold Coast, QLD, Australia, December 12-15, 2016, Proceedings 12},
  year = {2016},
  pages = {19--34}
}
</pre></td>
</tr>
<tr id="oggy2016CCTV" class="entry">
	<td>Arandjelovic O, Pham DS and Venkatesh S (2016), <i>"CCTV Scene Perspective Distortion Estimation From Low-Level Motion Features"</i>, IEEE Transactions on Circuits and Systems for Video Technology., May, 2016.  Vol. 26(5), pp. 939-949.
	<p class="infolinks">[<a href="javascript:toggleInfo('oggy2016CCTV','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('oggy2016CCTV','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1109/TCSVT.2015.2424055" target="_blank">DOI</a>] [<a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7088571" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_oggy2016CCTV" class="abstract noshow">
	<td><b>Abstract</b>: Our aim is to estimate the perspective-effected geometric distortion of a scene from a video feed. In contrast to most related previous work, in this task we are constrained to use low-level spatiotemporally local motion features only. This particular challenge arises in many semiautomatic surveillance systems that alert a human operator to potential abnormalities in the scene. Low-level spatiotemporally local motion features are sparse (and thus require comparatively little storage space) and sufficiently powerful in the context of video abnormality detection to reduce the need for human intervention by more than 100-fold. This paper introduces three significant contributions. First, we describe a dense algorithm for perspective estimation, which uses motion features to estimate the perspective distortion at each image locus and then polls all such local estimates to arrive at the globally best estimate. Second, we also present an alternative coarse algorithm that subdivides the image frame into blocks and uses motion features to derive block-specific motion characteristics and constrain the relationships between these characteristics, with the perspective estimate emerging as a result of a global optimization scheme. Third, we report the results of an evaluation using nine large sets acquired using existing closed-circuit television cameras, not installed specifically for the purposes of this paper. Our findings demonstrate that both proposed methods are successful, their accuracy matching that of human labeling using complete visual data (by the constraints of the setup unavailable to our algorithms).</td>
</tr>
<tr id="bib_oggy2016CCTV" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{oggy2016CCTV,
  author = {O. Arandjelovic and D. S. Pham and S. Venkatesh},
  title = {CCTV Scene Perspective Distortion Estimation From Low-Level Motion Features},
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  year = {2016},
  volume = {26},
  number = {5},
  pages = {939-949},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7088571},
  doi = {10.1109/TCSVT.2015.2424055}
}
</pre></td>
</tr>
<tr id="pham2016achieving" class="entry">
	<td>Pham D-S, Arandjelovic O and Venkatesh S (2016), <i>"Achieving stable subspace clustering by post-processing generic clustering results"</i>, In 2016 International Joint Conference on Neural Networks (IJCNN). , pp. 2390-2396.
	<p class="infolinks"> [<a href="javascript:toggleInfo('pham2016achieving','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_pham2016achieving" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{pham2016achieving,
  author = {Pham, Duc-Son and Arandjelovic, Ognjen and Venkatesh, Svetha},
  title = {Achieving stable subspace clustering by post-processing generic clustering results},
  booktitle = {2016 International Joint Conference on Neural Networks (IJCNN)},
  year = {2016},
  pages = {2390--2396}
}
</pre></td>
</tr>
<tr id="Pham2016Deepcare" class="entry">
	<td>Pham T, Tran T, Phung D and Venkatesh S (2016), <i>"DeepCare: A Deep Dynamic Memory Model for Predictive Medicine"</i>, In Pacific-Asia Conference on Knowledge Discovery and Data Mining. , pp. 30-41. Springer International Publishing.
	<p class="infolinks">[<a href="javascript:toggleInfo('Pham2016Deepcare','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Pham2016Deepcare','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1007/978-3-319-31750-2_3" target="_blank">DOI</a>] [<a href="http://dx.doi.org/10.1007/978-3-319-31750-2_3" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Pham2016Deepcare" class="abstract noshow">
	<td><b>Abstract</b>: Personalized predictive medicine necessitates modeling of patient illness and care processes, which inherently have long-term temporal dependencies. Healthcare observations, recorded in electronic medical records, are episodic and irregular in time. We introduce DeepCare, a deep dynamic neural network that reads medical records and predicts future medical outcomes. At the data level, DeepCare models patient health state trajectories with explicit memory of illness. Built on Long Short-Term Memory (LSTM), DeepCare introduces time parameterizations to handle irregular timing by moderating the forgetting and consolidation of illness memory. DeepCare also incorporates medical interventions that change the course of illness and shape future medical risk. Moving up to the health state level, historical and present health states are then aggregated through multiscale temporal pooling, before passing through a neural network that estimates future outcomes. We demonstrate the efficacy of DeepCare for disease progression modeling and readmission prediction in diabetes, a chronic disease with large economic burden. The results show improved modeling and risk prediction accuracy.</td>
</tr>
<tr id="bib_Pham2016Deepcare" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{Pham2016Deepcare,
  author = {Pham, Trang and Tran, Truyen and Phung, Dinh and Venkatesh, Svetha},
  editor = {Bailey, James and Khan, Latifur and Washio, Takashi and Dobbie, Gill and Huang, Zhexue Joshua and Wang, Ruili},
  title = {DeepCare: A Deep Dynamic Memory Model for Predictive Medicine},
  booktitle = {Pacific-Asia Conference on Knowledge Discovery and Data Mining},
  publisher = {Springer International Publishing},
  year = {2016},
  pages = {30--41},
  url = {http://dx.doi.org/10.1007/978-3-319-31750-2_3},
  doi = {10.1007/978-3-319-31750-2_3}
}
</pre></td>
</tr>
<tr id="pham2016faster" class="entry">
	<td>Pham T, Tran T, Phung D and Venkatesh S (2016), <i>"Faster Training of Very Deep Networks Via p-Norm Gates"</i>, In Proceedings of International Conference on Pattern Recognition. , pp. 3542-3547.
	<p class="infolinks">[<a href="javascript:toggleInfo('pham2016faster','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('pham2016faster','bibtex')">BibTeX</a>] [<a href="http://prada-research.net/~truyen/papers/flexible_gating.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_pham2016faster" class="abstract noshow">
	<td><b>Abstract</b>: A major contributing factor to the recent advances in deep neural networks is structural units that let sensory information and gradients to propagate easily. Gating is one such structure that acts as a flow control. Gates are employed in many recent state-of-the-art recurrent models such as LSTM and GRU, and feedforward models such as Residual Nets and Highway Networks. This enables learning in very deep networks with hundred layers and helps achieve record-breaking results in vision (e.g., ImageNet with Residual Nets) and NLP (e.g., machine translation with GRU). However, there is limited work in analysing the role of gating in the learning process. In this paper, we propose a flexible p-norm gating scheme, which allows usercontrollable flow and as a consequence, improve the learning speed. This scheme subsumes other existing gating schemes, including those in GRU, Highway Networks and Residual Nets as special cases. Experiments on large sequence and vector datasets demonstrate that the proposed gating scheme helps improve the learning speed significantly without extra overhead.</td>
</tr>
<tr id="bib_pham2016faster" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{pham2016faster,
  author = {Pham, Trang and Tran, Truyen and Phung, Dinh and Venkatesh, Svetha},
  title = {Faster Training of Very Deep Networks Via p-Norm Gates},
  booktitle = {Proceedings of International Conference on Pattern Recognition},
  year = {2016},
  pages = {3542--3547},
  url = {http://prada-research.net/&nbsp;truyen/papers/flexible_gating.pdf}
}
</pre></td>
</tr>
<tr id="saha2016framework" class="entry">
	<td>Saha B, Nguyen T, Phung D and Venkatesh S (2016), <i>"A Framework for Classifying Online Mental Health-Related Communities With an Interest in Depression"</i>, IEEE Journal of Biomedical and Health Informatics.  Vol. 20(4), pp. 1008-1015.
	<p class="infolinks">[<a href="javascript:toggleInfo('saha2016framework','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('saha2016framework','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1109/JBHI.2016.2543741" target="_blank">DOI</a>] [<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7436759" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_saha2016framework" class="abstract noshow">
	<td><b>Abstract</b>: Mental illness has a deep impact on individuals, families, and by extension, society as a whole. Social networks allow individuals with mental disorders to communicate with others sufferers via online communities, providing an invaluable resource for studies on textual signs of psychological health problems. Mental disorders often occur in combinations, e.g., a patient with an anxiety disorder may also develop depression. This co-occurring mental health condition provides the focus for our work on classifying online communities with an interest in depression. For this, we have crawled a large body of 620 000 posts made by 80 000 users in 247 online communities. We have extracted the topics and psycholinguistic features expressed in the posts, using these as inputs to our model. Following a machine learning technique, we have formulated a joint modeling framework in order to classify mental health-related co-occurring online communities from these features. Finally, we performed empirical validation of the model on the crawled dataset where our model outperforms recent state-of-the-art baselines.</td>
</tr>
<tr id="bib_saha2016framework" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{saha2016framework,
  author = {B. Saha and T. Nguyen and D. Phung and S. Venkatesh},
  title = {A Framework for Classifying Online Mental Health-Related Communities With an Interest in Depression},
  journal = {IEEE Journal of Biomedical and Health Informatics},
  year = {2016},
  volume = {20},
  number = {4},
  pages = {1008-1015},
  url = {http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7436759},
  doi = {10.1109/JBHI.2016.2543741}
}
</pre></td>
</tr>
<tr id="saha2016multiple" class="entry">
	<td>Saha B, Gupta S, Phung D and Venkatesh S (2016), <i>"Multiple task transfer learning with small sample sizes"</i>, Knowledge and Information Systems.  Vol. 46(2), pp. 315-342. Springer.
	<p class="infolinks">[<a href="javascript:toggleInfo('saha2016multiple','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('saha2016multiple','bibtex')">BibTeX</a>] [<a href="http://link.springer.com/article/10.1007/s10115-015-0821-z" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_saha2016multiple" class="abstract noshow">
	<td><b>Abstract</b>: Prognosis, such as predicting mortality, is common in medicine. When confronted with small numbers of samples, as in rare medical conditions, the task is challenging. We propose a framework for classification with data with small numbers of samples. Conceptually, our solution is a hybrid of multi-task and transfer learning, employing data samples from source tasks as in transfer learning, but considering all tasks together as in multi-task learning. Each task is modelled jointly with other related tasks by directly augmenting the data from other tasks. The degree of augmentation depends on the task relatedness and is estimated directly from the data. We apply the model on three diverse real-world data sets (healthcare data, handwritten digit data and face data) and show that our method outperforms several state-of-the-art multi-task learning baselines. We extend the model for online multi-task learning where the model parameters are incrementally updated given new data or new tasks. The novelty of our method lies in offering a hybrid multi-task/transfer learning model to exploit sharing across tasks at the data-level and joint parameter learning.</td>
</tr>
<tr id="bib_saha2016multiple" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{saha2016multiple,
  author = {Saha, Budhaditya and Gupta, Sunil and Phung, Dinh and Venkatesh, Svetha},
  title = {Multiple task transfer learning with small sample sizes},
  journal = {Knowledge and Information Systems},
  publisher = {Springer},
  year = {2016},
  volume = {46},
  number = {2},
  pages = {315--342},
  url = {http://link.springer.com/article/10.1007/s10115-015-0821-z}
}
</pre></td>
</tr>
<tr id="saha2016transferICPR" class="entry">
	<td>Saha B, Gupta S, Phung D and Venkatesh S (2016), <i>"Transfer Learning for Rare Cancer Problems via Discriminative Sparse Gaussian Graphical Model"</i>, In 23rd International Conference on Pattern Recognition (ICPR 2016). , pp. 537-542.
	<p class="infolinks">[<a href="javascript:toggleInfo('saha2016transferICPR','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('saha2016transferICPR','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="abs_saha2016transferICPR" class="abstract noshow">
	<td><b>Abstract</b>: Mortality prediction of rare cancer types with a small number of high-dimensional samples is a challenging task. We propose a transfer learning model where both classes in rare cancers (target task) are modeled in a joint framework by transferring knowledge from the source task. The knowledge transfer is at the data level where only “related” data points are chosen to train the target task. Moreover, both positive and negative class in training enhances the discrimination power of the proposed framework. Overall, this approach boosts the generalization performance of target task with a small number of data points. The formulation of the proposed framework is convex and expressed as a primal problem. We convert this to a dual problem and efficiently solve by alternating direction multipliers method. Our experiments with both synthetic and three real-world datasets show that our framework outperforms state-of-the-art single-task, multi-task, and transfer learning baselines.</td>
</tr>
<tr id="bib_saha2016transferICPR" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{saha2016transferICPR,
  author = {Saha, Budhaditya and Gupta, Sunil and Phung, Dinh and Venkatesh, Svetha},
  title = {Transfer Learning for Rare Cancer Problems via Discriminative Sparse Gaussian Graphical Model},
  booktitle = {23rd International Conference on Pattern Recognition (ICPR 2016)},
  year = {2016},
  pages = {537--542}
}
</pre></td>
</tr>
<tr id="shilton2016simple" class="entry">
	<td>Shilton A, Rana S, Gupta S and Venkatesh S (2016), <i>"A Simple Recursive Algorithm for calculating Expected Hypervolume Improvement"</i>, In Proceedings of NIPS Workshop on Bayesian Optimization: Black-box Optimization and Beyond, BayesOpt 2016. , pp. 1-5.
	<p class="infolinks">[<a href="javascript:toggleInfo('shilton2016simple','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('shilton2016simple','bibtex')">BibTeX</a>] [<a href="https://bayesopt.github.io/papers/2016/Shilton.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_shilton2016simple" class="abstract noshow">
	<td><b>Abstract</b>: In multi-objective optimisation, expected hypervolume improvement is a popular metric for assessing the merit of candidate solutions to guide the optimisation process. However the computational cost of calculating the EHI can become prohibitive, particularly as the number of objective functions increases. In this paper we present a new recursive algorithm for calculating the EHI. We show that the algorithm is simple to implement and significantly faster than alternative methods.</td>
</tr>
<tr id="bib_shilton2016simple" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{shilton2016simple,
  author = {Shilton, Alistair and Rana, Santu and Gupta, Sunil and Venkatesh, Svetha},
  title = {A Simple Recursive Algorithm for calculating Expected Hypervolume Improvement},
  booktitle = {Proceedings of NIPS Workshop on Bayesian Optimization: Black-box Optimization and Beyond, BayesOpt 2016},
  year = {2016},
  pages = {1--5},
  url = {https://bayesopt.github.io/papers/2016/Shilton.pdf}
}
</pre></td>
</tr>
<tr id="shiva2016forecastingICHI" class="entry">
	<td>Gopakumar S, Tran T, Luo W, Phung D and Venkatesh S (2016), <i>"Forecasting patient outflow from wards having no real-time clinical data"</i>, In Proceedings of IEEE International Conference on Health Informatics (ICHI). , pp. 177-183.
	<p class="infolinks">[<a href="javascript:toggleInfo('shiva2016forecastingICHI','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('shiva2016forecastingICHI','bibtex')">BibTeX</a>] [<a href="http://prada-research.net/~shiv/pubs/ichi_2016.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_shiva2016forecastingICHI" class="abstract noshow">
	<td><b>Abstract</b>: Modelling patient flow is crucial in understanding resource demand and prioritization. To date, there has been limited work in predicting ward-level discharges. Our study investigates forecasting total next-day discharges from an open ward. In the absence of real-time clinical data, we propose to construct a feature set from patient demographics, ward data and discharge time series to derive a random forest model for forecasting daily discharge. Using data from a general ward of a large regional Australian hospital, we compared our random forest model with a classical auto-regressive integrated moving average (ARIMA) for 12,141 patient visits over 1826 days. Forecasting quality was measured using Mean Forecast Error, Mean Absolute Error, symmetric Mean Absolute Percentage Error and Root Mean Square Error. When compared to the baseline model, next day discharge forecasts using random forests achieved 17.4 % improvement in Mean Absolute Error, for all days in the year 2014.</td>
</tr>
<tr id="bib_shiva2016forecastingICHI" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{shiva2016forecastingICHI,
  author = {Gopakumar, Shivapratap and Tran, Truyen and Luo, Wei and Phung, Dinh and Venkatesh, Svetha},
  title = {Forecasting patient outflow from wards having no real-time clinical data},
  booktitle = {Proceedings of IEEE International Conference on Health Informatics (ICHI)},
  year = {2016},
  pages = {177--183},
  url = {http://prada-research.net/&nbsp;shiv/pubs/ichi_2016.pdf}
}
</pre></td>
</tr>
<tr id="shiva2016forecastingJMIR" class="entry">
	<td>Gopakumar S, Tran T, Luo W, Phung D and Venkatesh S (2016), <i>"Forecasting Daily Patient Outflow From a Ward Having No Real-Time Clinical Data"</i>, JMIR Med Inform., Jul, 2016.  Vol. 4(3), pp. e25.
	<p class="infolinks">[<a href="javascript:toggleInfo('shiva2016forecastingJMIR','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('shiva2016forecastingJMIR','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.2196/medinform.5650" target="_blank">DOI</a>] [<a href="http://medinform.jmir.org/2016/3/e25/" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_shiva2016forecastingJMIR" class="abstract noshow">
	<td><b>Abstract</b>: Objective: Our study investigates different models to forecast the total number of next-day discharges from an open ward having no real-time clinical data. Methods: We compared 5 popular regression algorithms to model total next-day discharges: (1) autoregressive integrated moving average (ARIMA), (2) the autoregressive moving average with exogenous variables (ARMAX), (3) k-nearest neighbor regression, (4) random forest regression, and (5) support vector regression. Although the autoregressive integrated moving average model relied on past 3-month discharges, nearest neighbor forecasting used median of similar discharges in the past in estimating next-day discharge. In addition, the ARMAX model used the day of the week and number of patients currently in ward as exogenous variables. For the random forest and support vector regression models, we designed a predictor set of 20 patient features and 88 ward-level features. Results: Our data consisted of 12,141 patient visits over 1826 days. Forecasting quality was measured using mean forecast error, mean absolute error, symmetric mean absolute percentage error, and root mean square error. When compared with a moving average prediction model, all 5 models demonstrated superior performance with the random forests achieving 22.7&#37; improvement in mean absolute error, for all days in the year 2014. Conclusions: In the absence of clinical information, our study recommends using patient-level and ward-level data in predicting next-day discharges. Random forest and support vector regression models are able to use all available features from such data, resulting in superior performance over traditional autoregressive methods. An intelligent estimate of available beds in wards plays a crucial role in relieving access block in emergency departments. </td>
</tr>
<tr id="bib_shiva2016forecastingJMIR" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{shiva2016forecastingJMIR,
  author = {Gopakumar, Shivapratap and Tran, Truyen and Luo, Wei and Phung, Dinh and Venkatesh, Svetha},
  title = {Forecasting Daily Patient Outflow From a Ward Having No Real-Time Clinical Data},
  journal = {JMIR Med Inform},
  year = {2016},
  volume = {4},
  number = {3},
  pages = {e25},
  url = {http://medinform.jmir.org/2016/3/e25/},
  doi = {10.2196/medinform.5650}
}
</pre></td>
</tr>
<tr id="Subramanian_etal_16Bayesian" class="entry">
	<td>Subramanian S, Rana S, Gupta S, Sivakumar PB, Velayutham S and Venkatesh S (2016), <i>"Bayesian Nonparametric Multiple Instance Regression"</i>, In 23rd International Conference on Pattern Recognition (ICPR). , pp. 3661-3666.
	<p class="infolinks">[<a href="javascript:toggleInfo('Subramanian_etal_16Bayesian','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Subramanian_etal_16Bayesian','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="abs_Subramanian_etal_16Bayesian" class="abstract noshow">
	<td><b>Abstract</b>: Multiple Instance Regression jointly models a set of instances and its corresponding real-valued output. We present a novel multiple instance regression model that infers a subset of instances in each bag that best describes the bag label and uses them to learn a predictive model in a unified framework. We assume that instances in each bag are drawn from a mixture distribution and thus naturally form groups, and instances from one of this group explain the bag label. The largest cluster is assumed to be correlated with the label. We evaluate this model on the crop yield prediction and aerosol depth prediction problems. The predictive accuracy of our model is better than the state of the art MIR methods.</td>
</tr>
<tr id="bib_Subramanian_etal_16Bayesian" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{Subramanian_etal_16Bayesian,
  author = {Subramanian, S. and Rana, S. and Gupta, S. and Sivakumar, P. B. and Velayutham, S. and Venkatesh, S.},
  title = {Bayesian Nonparametric Multiple Instance Regression},
  booktitle = {23rd International Conference on Pattern Recognition (ICPR)},
  year = {2016},
  pages = {3661--3666}
}
</pre></td>
</tr>
<tr id="thanh2016cascade" class="entry">
	<td>Nguyen TD, Gupta S, Rana S, Nguyen V and Venkatesh S (2016), <i>"Cascade Bayesian Optimization"</i>, In 29th Australasian Joint Conference on Artificial Intelligence (AI 2016), Hobart. , pp. 268-280.
	<p class="infolinks"> [<a href="javascript:toggleInfo('thanh2016cascade','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_thanh2016cascade" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{thanh2016cascade,
  author = {Nguyen, Thanh Dai and Gupta, Sunil and Rana, Santu and Nguyen, Vu and Venkatesh, Svetha},
  title = {Cascade Bayesian Optimization},
  booktitle = {29th Australasian Joint Conference on Artificial Intelligence (AI 2016), Hobart},
  year = {2016},
  pages = {268--280}
}
</pre></td>
</tr>
<tr id="thanhNguyen2016privacy" class="entry">
	<td>Nguyen TD, Gupta S, Rana S and Venkatesh S (2016), <i>"Privacy Aware K-Means Clustering with High Utility"</i>, In Pacific-Asia Conference on Knowledge Discovery and Data Mining. , pp. 388-400. Springer International Publishing.
	<p class="infolinks">[<a href="javascript:toggleInfo('thanhNguyen2016privacy','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('thanhNguyen2016privacy','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1007/978-3-319-31750-2_31" target="_blank">DOI</a>] [<a href="http://dx.doi.org/10.1007/978-3-319-31750-2_31" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_thanhNguyen2016privacy" class="abstract noshow">
	<td><b>Abstract</b>: Privacy-preserving data mining aims to keep data safe, yet useful. But algorithms providing strong guarantees often end up with low utility. We propose a novel privacy preserving framework that thwarts an adversary from inferring an unknown data point by ensuring that the estimation error is almost invariant to the inclusion/exclusion of the data point. By focusing directly on the estimation error of the data point, our framework is able to significantly lower the perturbation required. We use this framework to propose a new privacy aware K-means clustering algorithm. Using both synthetic and real datasets, we demonstrate that the utility of this algorithm is almost equal to that of the unperturbed K-means, and at strict privacy levels, almost twice as good as compared to the differential privacy counterpart.</td>
</tr>
<tr id="bib_thanhNguyen2016privacy" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{thanhNguyen2016privacy,
  author = {Nguyen, Thanh Dai and Gupta, Sunil and Rana, Santu and Venkatesh, Svetha},
  editor = {Bailey, James and Khan, Latifur and Washio, Takashi and Dobbie, Gill and Huang, Zhexue Joshua and Wang, Ruili},
  title = {Privacy Aware K-Means Clustering with High Utility},
  booktitle = {Pacific-Asia Conference on Knowledge Discovery and Data Mining},
  publisher = {Springer International Publishing},
  year = {2016},
  pages = {388--400},
  url = {http://dx.doi.org/10.1007/978-3-319-31750-2_31},
  doi = {10.1007/978-3-319-31750-2_31}
}
</pre></td>
</tr>
<tr id="tran2016collaborative" class="entry">
	<td>Tran T, Phung D and Venkatesh S (2016), <i>"Collaborative filtering via sparse Markov random fields"</i>, Information Sciences.  Vol. 369, pp. 221-237.
	<p class="infolinks">[<a href="javascript:toggleInfo('tran2016collaborative','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('tran2016collaborative','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1016/j.ins.2016.06.027" target="_blank">DOI</a>] [<a href="http://arxiv.org/pdf/1602.02842.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_tran2016collaborative" class="abstract noshow">
	<td><b>Abstract</b>: Recommender systems play a central role in providing individualized access to information and services. This paper focuses on collaborative filtering, an approach that exploits the shared structure among mind-liked users and similar items. In particular, we focus on a formal probabilistic framework known as Markov random fields (MRF). We address the open problem of structure learning and introduce a sparsity-inducing algorithm to automatically estimate the interaction structures between users and between items. Item-item and user-user correlation networks are obtained as a by-product. Large-scale experiments on movie recommendation and date matching datasets demonstrate the power of the proposed method.</td>
</tr>
<tr id="bib_tran2016collaborative" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{tran2016collaborative,
  author = {Tran, Truyen and Phung, Dinh and Venkatesh, Svetha},
  title = {Collaborative filtering via sparse Markov random fields},
  journal = {Information Sciences},
  year = {2016},
  volume = {369},
  pages = {221--237},
  url = {http://arxiv.org/pdf/1602.02842.pdf},
  doi = {10.1016/j.ins.2016.06.027}
}
</pre></td>
</tr>
<tr id="Tran2016modelling" class="entry">
	<td>Tran T, Phung D and Venkatesh S (2016), <i>"Modelling human preferences for ranking and collaborative filtering: a probabilistic ordered partition approach"</i>, Knowledge and Information Systems.  Vol. 47(1), pp. 157-188.
	<p class="infolinks">[<a href="javascript:toggleInfo('Tran2016modelling','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('Tran2016modelling','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1007/s10115-015-0840-9" target="_blank">DOI</a>] [<a href="http://dx.doi.org/10.1007/s10115-015-0840-9" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_Tran2016modelling" class="abstract noshow">
	<td><b>Abstract</b>: Learning preference models from human generated data is an important task in modern information processing systems. Its popular setting consists of simple input ratings, assigned with numerical values to indicate their relevancy with respect to a specific query. Since ratings are often specified within a small range, several objects may have the same ratings, thus creating ties among objects for a given query. Dealing with this phenomena presents a general problem of modelling preferences in the presence of ties and being query-specific. To this end, we present in this paper a novel approach by constructing probabilistic models directly on the collection of objects exploiting the combinatorial structure induced by the ties among them. The proposed probabilistic setting allows exploration of a super-exponential combinatorial state-space with unknown numbers of partitions and unknown order among them. Learning and inference in such a large state-space are challenging, and yet we present in this paper efficient algorithms to perform these tasks. Our approach exploits discrete choice theory, imposing generative process such that the finite set of objects is partitioned into subsets in a stagewise procedure, and thus reducing the state-space at each stage significantly. Efficient Markov chain Monte Carlo algorithms are then presented for the proposed models. We demonstrate that the model can potentially be trained in a large-scale setting of hundreds of thousands objects using an ordinary computer. In fact, in some special cases with appropriate model specification, our models can be learned in linear time. We evaluate the models on two application areas: (i) document ranking with the data from the Yahoo! challenge and (ii) collaborative filtering with movie data. We demonstrate that the models are competitive against state-of-the-arts.</td>
</tr>
<tr id="bib_Tran2016modelling" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{Tran2016modelling,
  author = {Tran, Truyen and Phung, Dinh and Venkatesh, Svetha},
  title = {Modelling human preferences for ranking and collaborative filtering: a probabilistic ordered partition approach},
  journal = {Knowledge and Information Systems},
  year = {2016},
  volume = {47},
  number = {1},
  pages = {157--188},
  url = {http://dx.doi.org/10.1007/s10115-015-0840-9},
  doi = {10.1007/s10115-015-0840-9}
}
</pre></td>
</tr>
<tr id="tran2016neuralchoice" class="entry">
	<td>Tran T, Phung D and Venkatesh S (2016), <i>"Neural Choice by Elimination via Highway Networks"</i>, In 5th PAKDD Workshop on Biologically Inspired Data Mining Techniques., April, 2016. , pp. 15-25.
	<p class="infolinks">[<a href="javascript:toggleInfo('tran2016neuralchoice','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('tran2016neuralchoice','bibtex')">BibTeX</a>] [<a href="http://prada-research.net/~truyen/papers/bdm16.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_tran2016neuralchoice" class="abstract noshow">
	<td><b>Abstract</b>: We introduce Neural Choice by Elimination, a new framework that integrates deep neural networks into probabilistic sequential choice models for learning to rank. Given a set of items to chose from, the elimination strategy starts with the whole item set and iteratively eliminates the least worthy item in the remaining subset. We prove that the choice by elimination is equivalent to marginalizing out the random Gompertz latent utilities. Coupled with the choice model is the recently introduced Neural Highway Networks for approximating arbitrarily complex rank functions. We evaluate the proposed framework on a large-scale public dataset with over 425K items, drawn from the Yahoo! learning to rank challenge. It is demonstrated that the proposed method is competitive against state-of-the-art learning to rank methods.</td>
</tr>
<tr id="bib_tran2016neuralchoice" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{tran2016neuralchoice,
  author = {Tran, Truyen and Phung, Dinh and Venkatesh, Svetha},
  title = {Neural Choice by Elimination via Highway Networks},
  booktitle = {5th PAKDD Workshop on Biologically Inspired Data Mining Techniques},
  year = {2016},
  pages = {15--25},
  url = {http://prada-research.net/&nbsp;truyen/papers/bdm16.pdf}
}
</pre></td>
</tr>
<tr id="tran2016preterm" class="entry">
	<td>Tran T, Luo W, Phung D, Morris J, Rickard K and Venkatesh S (2016), <i>"Preterm Birth Prediction: Deriving Stable and Interpretable Rules from High Dimensional Data"</i>, In Machine Learning in Healthcare. , pp. 164-177.
	<p class="infolinks">[<a href="javascript:toggleInfo('tran2016preterm','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('tran2016preterm','bibtex')">BibTeX</a>] [<a href="http://proceedings.mlr.press/v56/Tran16.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_tran2016preterm" class="abstract noshow">
	<td><b>Abstract</b>: Preterm births occur at an alarming rate of 10-15%. Preemies have a higher risk of infant mortality, developmental retardation and long-term disabilities. Predicting preterm birth is difficult, even for the most experienced clinicians. The most well-designed clinical study thus far reaches a modest sensitivity of 18.2–24.2% at specificity of 28.6–33.3%. We take a different approach by exploiting databases of normal hospital operations. We aims are twofold: (i) to derive an easy-to-use, interpretable prediction rule with quantified uncertainties, and (ii) to construct accurate classifiers for preterm birth prediction. Our approach is to automatically generate and select from hundreds (if not thousands) of possible predictors using stability-aware techniques. Derived from a large database of 15,814 women, our simplified prediction rule with only 10 items has sensitivity of 62.3% at specificity of 81.5%.</td>
</tr>
<tr id="bib_tran2016preterm" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{tran2016preterm,
  author = {Tran, Truyen and Luo, Wei and Phung, Dinh and Morris, Jonathan and Rickard, Kristen and Venkatesh, Svetha},
  title = {Preterm Birth Prediction: Deriving Stable and Interpretable Rules from High Dimensional Data},
  booktitle = {Machine Learning in Healthcare},
  year = {2016},
  pages = {164--177},
  url = {http://proceedings.mlr.press/v56/Tran16.pdf}
}
</pre></td>
</tr>
<tr id="vellanki2016computer" class="entry">
	<td>Vellanki P, Greenhill S, Duong T, Phung D, Venkatesh S, Godwin J, Achary KV and Varkey B (2016), <i>"Computer assisted autism interventions for India"</i>, In Proceedings of the 28th Australian Conference on Computer-Human Interaction. , pp. 618-622.
	<p class="infolinks">[<a href="javascript:toggleInfo('vellanki2016computer','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('vellanki2016computer','bibtex')">BibTeX</a>] [<a href="http://dl.acm.org/citation.cfm?id=3011007" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_vellanki2016computer" class="abstract noshow">
	<td><b>Abstract</b>: Early intervention is critical for children with autism. To provide affordable computer assisted therapies for developing countries, we construct infrastructures for translating and adapting early intervention programs such as TOBY to an Indian context. A Hindi prototype is built and two trials are conducted, showing that the technology was accepted and that the children learnt skills using both language versions, with the children using the Hindi prototype achieving slightly better measurable outcomes.</td>
</tr>
<tr id="bib_vellanki2016computer" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{vellanki2016computer,
  author = {Vellanki, Pratibha and Greenhill, Stewart and Duong, Thi and Phung, Dinh and Venkatesh, Svetha and Godwin, Jayashree and Achary, Kishna V and Varkey, Blessin},
  title = {Computer assisted autism interventions for India},
  booktitle = {Proceedings of the 28th Australian Conference on Computer-Human Interaction},
  year = {2016},
  pages = {618--622},
  url = {http://dl.acm.org/citation.cfm?id=3011007}
}
</pre></td>
</tr>
<tr id="vu2016budgeted" class="entry">
	<td>Nguyen V, Rana S, Gupta S, Li C and Venkatesh S (2016), <i>"Budgeted Batch Bayesian Optimization"</i>, In IEEE International Conference on Data Mining (ICDM). , pp. 1107-1112.
	<p class="infolinks"> [<a href="javascript:toggleInfo('vu2016budgeted','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_vu2016budgeted" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{vu2016budgeted,
  author = {Nguyen, Vu and Rana, Santu and Gupta, Sunil and Li, Cheng and Venkatesh, Svetha},
  title = {Budgeted Batch Bayesian Optimization},
  booktitle = {IEEE International Conference on Data Mining (ICDM)},
  year = {2016},
  pages = {1107--1112}
}
</pre></td>
</tr>
<tr id="vu2016onepass" class="entry">
	<td>Nguyen V, Nguyen T, Le T, Phung D and Venkatesh S (2016), <i>"One-pass Logistic Regression for Label-drift and Large-scale Classification on Distributed Systems"</i>, In IEEE International Conference on Data Mining (ICDM). , pp. 1113-1118.
	<p class="infolinks"> [<a href="javascript:toggleInfo('vu2016onepass','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_vu2016onepass" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{vu2016onepass,
  author = {Nguyen, Vu and Nguyen, Tu and Le, T and Phung, Dinh and Venkatesh, Svetha},
  title = {One-pass Logistic Regression for Label-drift and Large-scale Classification on Distributed Systems},
  booktitle = {IEEE International Conference on Data Mining (ICDM)},
  year = {2016},
  pages = {1113--1118}
}
</pre></td>
</tr>
<tr id="vu2016think" class="entry">
	<td>Nguyen V, Gupta S, Rana S, Li C and Venkatesh S (2016), <i>"Think Globally, Act Locally: a Local Strategy for Bayesian Optimization"</i>, In Proceedings of NIPS Workshop on Bayesian Optimization: Black-box Optimization and Beyond, BayesOpt 2016. , pp. 5.
	<p class="infolinks">[<a href="javascript:toggleInfo('vu2016think','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('vu2016think','bibtex')">BibTeX</a>] [<a href="https://bayesopt.github.io/papers/2016/Nguyen.pdf" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_vu2016think" class="abstract noshow">
	<td><b>Abstract</b>: Bayesian optimization (BO) is a sample-efficient method for improving the performance of machine learning algorithms and laboratory experiments. We exploit the local property in BO to develop a new acquisition function, the expected local improvement (ELI) as an alternative to Expected Improvement (EI), aiming to address two underlying issues. First, we reduce the flatland issue in high dimension and second we allow greater explorative choices for batch BO unlike the existing strategies. We derive the convergence analysis using simple regret bound. We further demonstrate that the proposed strategy gains substantial performance improvement over the state-of-the-art baselines using the benchmark functions and real experiments on sequential and batch BO.</td>
</tr>
<tr id="bib_vu2016think" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{vu2016think,
  author = {Nguyen, Vu and Gupta, Sunil and Rana, Santu and Li, Cheng and Venkatesh, Svetha},
  title = {Think Globally, Act Locally: a Local Strategy for Bayesian Optimization},
  booktitle = {Proceedings of NIPS Workshop on Bayesian Optimization: Black-box Optimization and Beyond, BayesOpt 2016},
  year = {2016},
  pages = {5},
  url = {https://bayesopt.github.io/papers/2016/Nguyen.pdf}
}
</pre></td>
</tr>
</tbody>
</table>
<footer>
 <small>Created by <a href="http://jabref.sourceforge.net">JabRef</a> on 02/08/2019.</small>
</footer>
<!-- file generated by JabRef -->
</body>
</html>