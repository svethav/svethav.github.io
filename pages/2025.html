<!DOCTYPE HTML>
<html>
<head>
<title>JabRef references</title>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<script type="text/javascript">
<!--
// QuickSearch script for JabRef HTML export 
// Version: 3.0
//
// Copyright (c) 2006-2011, Mark Schenk
//
// This software is distributed under a Creative Commons Attribution 3.0 License
// http://creativecommons.org/licenses/by/3.0/
//
// Features:
// - intuitive find-as-you-type searching
//    ~ case insensitive
//    ~ ignore diacritics (optional)
//
// - search with/without Regular Expressions
// - match BibTeX key
//

// Search settings
var searchAbstract = true;	// search in abstract
var searchReview = true;	// search in review

var noSquiggles = true; 	// ignore diacritics when searching
var searchRegExp = false; 	// enable RegExp searches


if (window.addEventListener) {
	window.addEventListener("load",initSearch,false); }
else if (window.attachEvent) {
	window.attachEvent("onload", initSearch); }

function initSearch() {
	// check for quick search table and searchfield
	if (!document.getElementById('qs_table')||!document.getElementById('quicksearch')) { return; }

	// load all the rows and sort into arrays
	loadTableData();
	
	//find the query field
	qsfield = document.getElementById('qs_field');

	// previous search term; used for speed optimisation
	prevSearch = '';

	//find statistics location
	stats = document.getElementById('stat');
	setStatistics(-1);
	
	// set up preferences
	initPreferences();

	// shows the searchfield
	document.getElementById('quicksearch').style.display = 'block';
	document.getElementById('qs_field').onkeyup = quickSearch;
}

function loadTableData() {
	// find table and appropriate rows
	searchTable = document.getElementById('qs_table');
	var allRows = searchTable.getElementsByTagName('tbody')[0].getElementsByTagName('tr');

	// split all rows into entryRows and infoRows (e.g. abstract, review, bibtex)
	entryRows = new Array(); infoRows = new Array(); absRows = new Array(); revRows = new Array();

	// get data from each row
	entryRowsData = new Array(); absRowsData = new Array(); revRowsData = new Array(); 
	
	BibTeXKeys = new Array();
	
	for (var i=0, k=0, j=0; i<allRows.length;i++) {
		if (allRows[i].className.match(/entry/)) {
			entryRows[j] = allRows[i];
			entryRowsData[j] = stripDiacritics(getTextContent(allRows[i]));
			allRows[i].id ? BibTeXKeys[j] = allRows[i].id : allRows[i].id = 'autokey_'+j;
			j ++;
		} else {
			infoRows[k++] = allRows[i];
			// check for abstract/review
			if (allRows[i].className.match(/abstract/)) {
				absRows.push(allRows[i]);
				absRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			} else if (allRows[i].className.match(/review/)) {
				revRows.push(allRows[i]);
				revRowsData[j-1] = stripDiacritics(getTextContent(allRows[i]));
			}
		}
	}
	//number of entries and rows
	numEntries = entryRows.length;
	numInfo = infoRows.length;
	numAbs = absRows.length;
	numRev = revRows.length;
}

function quickSearch(){
	
	tInput = qsfield;

	if (tInput.value.length == 0) {
		showAll();
		setStatistics(-1);
		qsfield.className = '';
		return;
	} else {
		t = stripDiacritics(tInput.value);

		if(!searchRegExp) { t = escapeRegExp(t); }
			
		// only search for valid RegExp
		try {
			textRegExp = new RegExp(t,"i");
			closeAllInfo();
			qsfield.className = '';
		}
			catch(err) {
			prevSearch = tInput.value;
			qsfield.className = 'invalidsearch';
			return;
		}
	}
	
	// count number of hits
	var hits = 0;

	// start looping through all entry rows
	for (var i = 0; cRow = entryRows[i]; i++){

		// only show search the cells if it isn't already hidden OR if the search term is getting shorter, then search all
		if(cRow.className.indexOf('noshow')==-1 || tInput.value.length <= prevSearch.length){
			var found = false; 

			if (entryRowsData[i].search(textRegExp) != -1 || BibTeXKeys[i].search(textRegExp) != -1){ 
				found = true;
			} else {
				if(searchAbstract && absRowsData[i]!=undefined) {
					if (absRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
				if(searchReview && revRowsData[i]!=undefined) {
					if (revRowsData[i].search(textRegExp) != -1){ found=true; } 
				}
			}
			
			if (found){
				cRow.className = 'entry show';
				hits++;
			} else {
				cRow.className = 'entry noshow';
			}
		}
	}

	// update statistics
	setStatistics(hits)
	
	// set previous search value
	prevSearch = tInput.value;
}


// Strip Diacritics from text
// http://stackoverflow.com/questions/990904/javascript-remove-accents-in-strings

// String containing replacement characters for stripping accents 
var stripstring = 
    'AAAAAAACEEEEIIII'+
    'DNOOOOO.OUUUUY..'+
    'aaaaaaaceeeeiiii'+
    'dnooooo.ouuuuy.y'+
    'AaAaAaCcCcCcCcDd'+
    'DdEeEeEeEeEeGgGg'+
    'GgGgHhHhIiIiIiIi'+
    'IiIiJjKkkLlLlLlL'+
    'lJlNnNnNnnNnOoOo'+
    'OoOoRrRrRrSsSsSs'+
    'SsTtTtTtUuUuUuUu'+
    'UuUuWwYyYZzZzZz.';

function stripDiacritics(str){

    if(noSquiggles==false){
        return str;
    }

    var answer='';
    for(var i=0;i<str.length;i++){
        var ch=str[i];
        var chindex=ch.charCodeAt(0)-192;   // Index of character code in the strip string
        if(chindex>=0 && chindex<stripstring.length){
            // Character is within our table, so we can strip the accent...
            var outch=stripstring.charAt(chindex);
            // ...unless it was shown as a '.'
            if(outch!='.')ch=outch;
        }
        answer+=ch;
    }
    return answer;
}

// http://stackoverflow.com/questions/3446170/escape-string-for-use-in-javascript-regex
// NOTE: must escape every \ in the export code because of the JabRef Export...
function escapeRegExp(str) {
  return str.replace(/[-\[\]\/\{\}\(\)\*\+\?\.\\\^\$\|]/g, "\\$&");
}

function toggleInfo(articleid,info) {

	var entry = document.getElementById(articleid);
	var abs = document.getElementById('abs_'+articleid);
	var rev = document.getElementById('rev_'+articleid);
	var bib = document.getElementById('bib_'+articleid);
	
	if (abs && info == 'abstract') {
		abs.className.indexOf('noshow') == -1?abs.className = 'abstract noshow':abs.className = 'abstract show';
	} else if (rev && info == 'review') {
		rev.className.indexOf('noshow') == -1?rev.className = 'review noshow':rev.className = 'review show';
	} else if (bib && info == 'bibtex') {
		bib.className.indexOf('noshow') == -1?bib.className = 'bibtex noshow':bib.className = 'bibtex show';
	} else { 
		return;
	}

	// check if one or the other is available
	var revshow; var absshow; var bibshow;
	(abs && abs.className.indexOf('noshow') == -1)? absshow = true: absshow = false;
	(rev && rev.className.indexOf('noshow') == -1)? revshow = true: revshow = false;	
	(bib && bib.className.indexOf('noshow') == -1)? bibshow = true: bibshow = false;
	
	// highlight original entry
	if(entry) {
		if (revshow || absshow || bibshow) {
		entry.className = 'entry highlight show';
		} else {
		entry.className = 'entry show';
		}
	}
	
	// When there's a combination of abstract/review/bibtex showing, need to add class for correct styling
	if(absshow) {
		(revshow||bibshow)?abs.className = 'abstract nextshow':abs.className = 'abstract';
	} 
	if (revshow) {
		bibshow?rev.className = 'review nextshow': rev.className = 'review';
	}	
	
}

function setStatistics (hits) {
	if(hits < 0) { hits=numEntries; }
	if(stats) { stats.firstChild.data = hits + '/' + numEntries}
}

function getTextContent(node) {
	// Function written by Arve Bersvendsen
	// http://www.virtuelvis.com
	
	if (node.nodeType == 3) {
	return node.nodeValue;
	} // text node
	if (node.nodeType == 1 && node.className != "infolinks") { // element node
	var text = [];
	for (var chld = node.firstChild;chld;chld=chld.nextSibling) {
		text.push(getTextContent(chld));
	}
	return text.join("");
	} return ""; // some other node, won't contain text nodes.
}

function showAll(){
	closeAllInfo();
	for (var i = 0; i < numEntries; i++){ entryRows[i].className = 'entry show'; }
}

function closeAllInfo(){
	for (var i=0; i < numInfo; i++){
		if (infoRows[i].className.indexOf('noshow') ==-1) {
			infoRows[i].className = infoRows[i].className + ' noshow';
		}
	}
}

function clearQS() {
	qsfield.value = '';
	showAll();
}

function redoQS(){
	showAll();
	quickSearch(qsfield);
}

function updateSetting(obj){
	var option = obj.id;
	var checked = obj.value;

	switch(option)
	 {
	 case "opt_searchAbs":
	   searchAbstract=!searchAbstract;
	   redoQS();
	   break;
	 case "opt_searchRev":
	   searchReview=!searchReview;
	   redoQS();
	   break;
	 case "opt_useRegExp":
	   searchRegExp=!searchRegExp;
	   redoQS();
	   break;
	 case "opt_noAccents":
	   noSquiggles=!noSquiggles;
	   loadTableData();
	   redoQS();
	   break;
	 }
}

function initPreferences(){
	if(searchAbstract){document.getElementById("opt_searchAbs").checked = true;}
	if(searchReview){document.getElementById("opt_searchRev").checked = true;}
	if(noSquiggles){document.getElementById("opt_noAccents").checked = true;}
	if(searchRegExp){document.getElementById("opt_useRegExp").checked = true;}
	
	if(numAbs==0) {document.getElementById("opt_searchAbs").parentNode.style.display = 'none';}
	if(numRev==0) {document.getElementById("opt_searchRev").parentNode.style.display = 'none';}	
}

function toggleSettings(){
	var togglebutton = document.getElementById('showsettings');
	var settings = document.getElementById('settings');
	
	if(settings.className == "hidden"){
		settings.className = "show";
		togglebutton.innerText = "close settings";
		togglebutton.textContent = "close settings";
	}else{
		settings.className = "hidden";
		togglebutton.innerText = "settings...";		
		togglebutton.textContent = "settings...";
	}
}

-->
</script>
<style type="text/css">
body { background-color: white; font-family: Arial, sans-serif; font-size: 13px; line-height: 1.2; padding: 1em; color: #2E2E2E; width: 50em; margin: auto auto; }

form#quicksearch { width: auto; border-style: solid; border-color: gray; border-width: 1px 0px; padding: 0.7em 0.5em; display:none; position:relative; }
span#searchstat {padding-left: 1em;}

div#settings { margin-top:0.7em; /* border-bottom: 1px transparent solid; background-color: #efefef; border: 1px grey solid; */ }
div#settings ul {margin: 0; padding: 0; }
div#settings li {margin: 0; padding: 0 1em 0 0; display: inline; list-style: none; }
div#settings li + li { border-left: 2px #efefef solid; padding-left: 0.5em;}
div#settings input { margin-bottom: 0px;}

div#settings.hidden {display:none;}

#showsettings { border: 1px grey solid; padding: 0 0.5em; float:right; line-height: 1.6em; text-align: right; }
#showsettings:hover { cursor: pointer; }

.invalidsearch { background-color: red; }
input[type="button"] { background-color: #efefef; border: 1px #2E2E2E solid;}

table { border: 1px gray none; width: 100%; empty-cells: show; border-spacing: 0em 0.1em; margin: 1em 0em; }
th, td { border: none; padding: 0.5em; vertical-align: top; text-align: justify; }

td a { color: navy; text-decoration: none; }
td a:hover  { text-decoration: underline; }

tr.noshow { display: none;}
tr.highlight td { background-color: #EFEFEF; border-top: 2px #2E2E2E solid; font-weight: bold; }
tr.abstract td, tr.review td, tr.bibtex td { background-color: #EFEFEF; text-align: justify; border-bottom: 2px #2E2E2E solid; }
tr.nextshow td { border-bottom-style: none; }

tr.bibtex pre { width: 100%; overflow: auto; white-space: pre-wrap;}
p.infolinks { margin: 0.3em 0em 0em 0em; padding: 0px; }

@media print {
	p.infolinks, #qs_settings, #quicksearch, t.bibtex { display: none !important; }
	tr { page-break-inside: avoid; }
}
</style>
</head>
<body>

<form action="" id="quicksearch">
<input type="text" id="qs_field" autocomplete="off" placeholder="Type to search..." /> <input type="button" onclick="clearQS()" value="clear" />
<span id="searchstat">Matching entries: <span id="stat">0</span></span>
<div id="showsettings" onclick="toggleSettings()">settings...</div>
<div id="settings" class="hidden">
<ul>
<li><input type="checkbox" class="search_setting" id="opt_searchAbs" onchange="updateSetting(this)"><label for="opt_searchAbs"> include abstract</label></li>
<li><input type="checkbox" class="search_setting" id="opt_searchRev" onchange="updateSetting(this)"><label for="opt_searchRev"> include review</label></li>
<li><input type="checkbox" class="search_setting" id="opt_useRegExp" onchange="updateSetting(this)"><label for="opt_useRegExp"> use RegExp</label></li>
<li><input type="checkbox" class="search_setting" id="opt_noAccents" onchange="updateSetting(this)"><label for="opt_noAccents"> ignore accents</label></li>
</ul>
</div>
</form>
<table id="qs_table" border="1">
<tbody>
<tr id="le2025multi" class="entry">
	<td>Le H, Tran Q, Nguyen D, Do K, Mittal S, Ogueji K and Venkatesh S (2025), <i>"Multi-Reference Preference Optimization for Large Language Models"</i>, In AAAI Conference on Artificial Intelligence (AAAI). , pp. (accepted on Dec 10, 2024).
	<p class="infolinks"> [<a href="javascript:toggleInfo('le2025multi','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_le2025multi" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{le2025multi,
  author = {Le, Hung and Tran, Quan and Nguyen, Dung and Do, Kien and Mittal, Saloni and Ogueji, Kelechi and Venkatesh, Svetha},
  title = {Multi-Reference Preference Optimization for Large Language Models},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year = {2025},
  pages = {(accepted on Dec 10, 2024)},
  note = {(A* conference)}
}
</pre></td>
</tr>
<tr id="le2025stable" class="entry">
	<td>Le H, Do K, Nguyen D, Gupta S and Venkatesh S (2025), <i>"Stable Hadamard Memory: Revitalizing Memory-Augmented Agents for Reinforcement Learning"</i>, In International Conference on Learning Representations (ICLR). , pp. (accepted on Jan 23, 2025).
	<p class="infolinks"> [<a href="javascript:toggleInfo('le2025stable','bibtex')">BibTeX</a>]</p>
	</td>
</tr>
<tr id="bib_le2025stable" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{le2025stable,
  author = {Le, Hung and Do, Kien and Nguyen, Dung and Gupta, Sunil and Venkatesh, Svetha},
  title = {Stable Hadamard Memory: Revitalizing Memory-Augmented Agents for Reinforcement Learning},
  booktitle = {International Conference on Learning Representations (ICLR)},
  year = {2025},
  pages = {(accepted on Jan 23, 2025)},
  note = {(A* conference)}
}
</pre></td>
</tr>
<tr id="10992546" class="entry">
	<td>Ghosh B, Harikumar H, Venkatesh S and Rana S (2025), <i>"Targeted Manifold Manipulation Against Adversarial Attacks"</i>, In 2025 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML). Los Alamitos, CA, USA, April, 2025. , pp. 427-438. IEEE Computer Society.
	<p class="infolinks">[<a href="javascript:toggleInfo('10992546','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('10992546','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1109/SaTML64287.2025.00030" target="_blank">DOI</a>] [<a href="https://doi.ieeecomputersociety.org/10.1109/SaTML64287.2025.00030" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_10992546" class="abstract noshow">
	<td><b>Abstract</b>: Adversarial attacks on deep models are often guaranteed to find a small and innocuous perturbation to easily alter the class label of a test input. We use a novel Targeted Manifold Manipulation (TMM) approach to direct the gradients from the genuine data manifold toward carefully planted traps during such adversarial attacks. The traps are assigned an additional class label (Trapclass) to make the attacks falling in them easily identifiable. Whilst low-perturbation budget attacks will necessarily end up in the traps, high-perturbation budget attacks may escape but only end up far away from the data manifold. Since our manifold manipulation is enforced only locally, we show that such out-of-distribution data can be easily detected by noting the absence of traps around them. Our detection algorithm, denoted as TMM-Def avoids learning a separate model for attack detection and thus remains semantically aligned with the original classifier. Further, since we manipulate the adversarial distribution, it avoids the fundamental difficulty associated with overlapping distributions of clean and attack samples for usual, unmanipulated models. We use nine state-of-the-art adversarial attacks with six well-known image datasets to evaluate our proposed defense. Our results show that the proposed method can detect &nbsp;99% attacks whilst also being robust to semantic-preserving, transformations, and adaptive attacks.</td>
</tr>
<tr id="bib_10992546" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{10992546,
  author = {Ghosh, Banibrata and Harikumar, Haripriya and Venkatesh, Svetha and Rana, Santu},
  title = {Targeted Manifold Manipulation Against Adversarial Attacks},
  booktitle = {2025 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)},
  publisher = {IEEE Computer Society},
  year = {2025},
  pages = {427--438},
  url = {https://doi.ieeecomputersociety.org/10.1109/SaTML64287.2025.00030},
  doi = {10.1109/SaTML64287.2025.00030}
}
</pre></td>
</tr>
<tr id="AV2025113138" class="entry">
	<td>Arun Kumar AV, Shilton A, Gupta S, Ryan S, Abdolshah M, Le H, Rana S, Berk J, Rashid M and Venkatesh S (2025), <i>"Accelerated experimental design using a human–AI teaming framework"</i>, Knowledge-Based Systems.  Vol. 315, pp. 113138.
	<p class="infolinks">[<a href="javascript:toggleInfo('AV2025113138','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('AV2025113138','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1016/j.knosys.2025.113138" target="_blank">DOI</a>] [<a href="https://www.sciencedirect.com/science/article/pii/S0950705125001856" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_AV2025113138" class="abstract noshow">
	<td><b>Abstract</b>: In this paper we propose a human–AI teaming framework for the optimization of expensive black-box functions. Inspired by the intrinsic difficulty of extracting expert knowledge and distilling it back into AI models and by observations of human behavior in real-world experimental design, our proposed algorithm lets the human expert take the lead in the experimental process. The human expert can use their domain expertise to its full potential, while the AI plays the role of a muse, injecting novelty and searching for areas of weakness to break the human out of over-exploitation induced by cognitive entrenchment. We validate our proposed algorithm using synthetic data and with human experts performing real-world experiments.</td>
</tr>
<tr id="bib_AV2025113138" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{AV2025113138,
  author = {Arun Kumar A.V. and Alistair Shilton and Sunil Gupta and Shannon Ryan and Majid Abdolshah and Hung Le and Santu Rana and Julian Berk and Mahad Rashid and Svetha Venkatesh},
  title = {Accelerated experimental design using a human–AI teaming framework},
  journal = {Knowledge-Based Systems},
  year = {2025},
  volume = {315},
  pages = {113138},
  url = {https://www.sciencedirect.com/science/article/pii/S0950705125001856},
  doi = {10.1016/j.knosys.2025.113138}
}
</pre></td>
</tr>
<tr id="George2025" class="entry">
	<td>George TK, Semage BL, Rana S, Le H, Tran T, Gupta S and Venkatesh S (2025), <i>"LaGR-SEQ: Language-guided reinforcement learning with sample-efficient querying"</i>, Neural Computing and Applications. 
	<p class="infolinks">[<a href="javascript:toggleInfo('George2025','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('George2025','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1007/s00521-025-11156-y" target="_blank">DOI</a>] [<a href="https://doi.org/10.1007/s00521-025-11156-y" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_George2025" class="abstract noshow">
	<td><b>Abstract</b>: Large language models (LLMs) have recently demonstrated their impressive ability to provide context-aware responses via text. This ability could potentially be used to predict plausible solutions in sequential decision making tasks pertaining to pattern completion. For example, by observing a partial stack of cubes, LLMs can predict the correct sequence in which the remaining cubes should be stacked by extrapolating the observed patterns (e.g., cube sizes, colors or other attributes) in the partial stack. In this work, we introduce LaGR (language-guided reinforcement learning), which uses this predictive ability of LLMs to propose solutions to tasks that have been partially completed by a primary reinforcement learning (RL) agent, in order to subsequently guide the latter’s training. However, as RL training is generally not sample-efficient, deploying this approach would inherently imply that the LLM be repeatedly queried for solutions; a process that can be expensive and infeasible. To address this issue, we introduce SEQ (sample-efficient querying), where we simultaneously train a secondary RL agent to decide when the LLM should be queried for solutions. Specifically, we use the quality of the solutions emanating from the LLM as the reward to train this agent. We show that our proposed framework LaGR-SEQ enables more efficient primary RL training, while simultaneously minimizing the number of queries to the LLM. We demonstrate our approach on a series of tasks and highlight the advantages of our approach, along with its limitations and potential future research directions.</td>
</tr>
<tr id="bib_George2025" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{George2025,
  author = {George, Thommen Karimpanal and Semage, Buddhika Laknath and Rana, Santu and Le, Hung and Tran, Truyen and Gupta, Sunil and Venkatesh, Svetha},
  title = {LaGR-SEQ: Language-guided reinforcement learning with sample-efficient querying},
  journal = {Neural Computing and Applications},
  year = {2025},
  url = {https://doi.org/10.1007/s00521-025-11156-y},
  doi = {10.1007/s00521-025-11156-y}
}
</pre></td>
</tr>
<tr id="RYAN2025105364" class="entry">
	<td>Ryan S, Le H, Berk J, Kumar AA and Venkatesh S (2025), <i>"Physics-informed machine learning for predicting the ballistic limit of whipple shields"</i>, International Journal of Impact Engineering.  Vol. 203, pp. 105364.
	<p class="infolinks">[<a href="javascript:toggleInfo('RYAN2025105364','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('RYAN2025105364','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1016/j.ijimpeng.2025.105364" target="_blank">DOI</a>] [<a href="https://www.sciencedirect.com/science/article/pii/S0734743X25001459" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_RYAN2025105364" class="abstract noshow">
	<td><b>Abstract</b>: Data driven machine learning (ML) models can provide improved accuracy over semi-analytical ballistic limit equations (BLEs) for predicting the outcome of space debris impacts on spacecraft structures. However, they should not be applied beyond the scope of their training data which limits their utilisation in mission risk assessments. We develop and demonstrate two approaches for incorporating physics knowledge, in the form of existing BLEs, into ML models to mitigate this limitation. The resulting physics-informed models provide modestly improved classification accuracy when applied on a database of experimental records as well as improved agreement with BLEs when applied outside the scope of the training dataset, compared to previous data-driven ML models.</td>
</tr>
<tr id="bib_RYAN2025105364" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{RYAN2025105364,
  author = {Shannon Ryan and Hung Le and Julian Berk and AV Arun Kumar and Svetha Venkatesh},
  title = {Physics-informed machine learning for predicting the ballistic limit of whipple shields},
  journal = {International Journal of Impact Engineering},
  year = {2025},
  volume = {203},
  pages = {105364},
  url = {https://www.sciencedirect.com/science/article/pii/S0734743X25001459},
  doi = {10.1016/j.ijimpeng.2025.105364}
}
</pre></td>
</tr>
<tr id="doi:10.1021/acs.jpcc.5c00954" class="entry">
	<td>Tawfik SA, Berk J, Walsh TR, Rana S and Venkatesh S (2025), <i>"Accelerated Discovery of Solid-State Electrolytes Using Bayesian Optimization"</i>, The Journal of Physical Chemistry C.  Vol. 129(13), pp. 6148-6156.
	<p class="infolinks"> [<a href="javascript:toggleInfo('doi:10.1021/acs.jpcc.5c00954','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1021/acs.jpcc.5c00954" target="_blank">DOI</a>] [<a href="https://doi.org/10.1021/acs.jpcc.5c00954" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="bib_doi:10.1021/acs.jpcc.5c00954" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{doi:10.1021/acs.jpcc.5c00954,
  author = {Tawfik, Sherif Abdulkader and Berk, Julian and Walsh, Tiffany R. and Rana, Santu and Venkatesh, Svetha},
  title = {Accelerated Discovery of Solid-State Electrolytes Using Bayesian Optimization},
  journal = {The Journal of Physical Chemistry C},
  year = {2025},
  volume = {129},
  number = {13},
  pages = {6148--6156},
  url = {https://doi.org/10.1021/acs.jpcc.5c00954},
  doi = {10.1021/acs.jpcc.5c00954}
}
</pre></td>
</tr>
<tr id="aliza2025futureproofing" class="entry">
	<td>Werner-Seidler A, Mackinnon A, Batterham PJ, Calear AL, Larsen ME, Torok M, O’Dea B, Maston K, Huckvale K, Fujimoto H, Johnston L, Brown L, Batholomew A, Bal D, Beames JR, Skinner SR, Boydell KM, Schweizer S, Lingam R, Perry Y, Hudson JL, Oei JL, Steinbeck K, Teesson M, Venkatesh S and Christensen H (2025), <i>"Future Proofing Study: a cluster randomised controlled trial evaluating the effectiveness of a universal school-based cognitive-behavioural programme for adolescent depression"</i>, BMJ Mental Health.  Vol. 28(1), pp. e301426.
	<p class="infolinks"> [<a href="javascript:toggleInfo('aliza2025futureproofing','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1136/bmjment-2024-301426" target="_blank">DOI</a>]</p>
	</td>
</tr>
<tr id="bib_aliza2025futureproofing" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{aliza2025futureproofing,
  author = {Aliza Werner-Seidler and Andrew Mackinnon and Philip J Batterham and Alison L Calear and Mark E Larsen and Michelle Torok and Bridianne O’Dea and Kate Maston and Kit Huckvale and Hiroko Fujimoto and Lara Johnston and Lyndsay Brown and Alexandra Batholomew and Debopriyo Bal and Joanne R Beames and Susan Rachel Skinner and Katherine M Boydell and Susanne Schweizer and Raghu Lingam and Yael Perry and Jennifer L Hudson and Ju Lee Oei and Katharine Steinbeck and Maree Teesson and Svetha Venkatesh and Helen Christensen},
  title = {Future Proofing Study: a cluster randomised controlled trial evaluating the effectiveness of a universal school-based cognitive-behavioural programme for adolescent depression},
  journal = {BMJ Mental Health},
  year = {2025},
  volume = {28},
  number = {1},
  pages = {e301426},
  doi = {10.1136/bmjment-2024-301426}
}
</pre></td>
</tr>
<tr id="HOLM2025109632" class="entry">
	<td>Holm NN, Le TM, Frølich A, Andersen O, Juul-Larsen HG, Stockmarr A and Venkatesh S (2025), <i>"amVAE: Age-aware multimorbidity clustering using variational autoencoders"</i>, Computers in Biology and Medicine.  Vol. 186, pp. 109632.
	<p class="infolinks">[<a href="javascript:toggleInfo('HOLM2025109632','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('HOLM2025109632','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1016/j.compbiomed.2024.109632" target="_blank">DOI</a>] [<a href="https://www.sciencedirect.com/science/article/pii/S0010482524017177" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_HOLM2025109632" class="abstract noshow">
	<td><b>Abstract</b>: Multimorbidity, the co-occurrence of multiple chronic conditions within the same individual, is increasing globally. This is a challenge for the single patients, as these individuals are subject to a heavy disease and treatment burden, yet evidence on the epidemiology and consequences of multimorbidity remains underexplored. Historically, studies aiming to understand multimorbidity patterns predominantly utilized cross-sectional data, neglecting the essential temporal dynamics which shape multimorbidity progression. Other studies based their analyses on small datasets, or populations only targeting certain sectors of the healthcare system. In this study, we (1) introduce a novel two-step multimodal Variational Autoencoder-based approach for temporal disease-based clustering (i.e. discovering age-aware multimorbidity clusters); (2) provide quantitative experiments for the robustness of our approach and the extracted temporal clusters; and (3) demonstrate how the temporal disease clusters obtained from our model can provide novel understanding of the development of multiple conditions over time and thus generate new hypotheses for different stages of multimorbidity and their associations. We trained and evaluated our models on a dataset containing the entire adult population of Denmark in the period 1995–2015, focusing on individuals suffering from chronic heart disease, including 766,596 individuals.</td>
</tr>
<tr id="bib_HOLM2025109632" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{HOLM2025109632,
  author = {Nikolaj Normann Holm and Thao Minh Le and Anne Frølich and Ove Andersen and Helle Gybel Juul-Larsen and Anders Stockmarr and Svetha Venkatesh},
  title = {amVAE: Age-aware multimorbidity clustering using variational autoencoders},
  journal = {Computers in Biology and Medicine},
  year = {2025},
  volume = {186},
  pages = {109632},
  url = {https://www.sciencedirect.com/science/article/pii/S0010482524017177},
  doi = {10.1016/j.compbiomed.2024.109632}
}
</pre></td>
</tr>
<tr id="10943488" class="entry">
	<td>Palakkadavath R, Le H, Nguyen-Tang T, Gupta S and Venkatesh S (2025), <i>"Fair Domain Generalization with Heterogeneous Sensitive Attributes Across Domains"</i>, In 2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV). , pp. 7389-7398.
	<p class="infolinks"> [<a href="javascript:toggleInfo('10943488','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1109/WACV61041.2025.00718" target="_blank">DOI</a>]</p>
	</td>
</tr>
<tr id="bib_10943488" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@inproceedings{10943488,
  author = {Palakkadavath, Ragja and Le, Hung and Nguyen-Tang, Thanh and Gupta, Sunil and Venkatesh, Svetha},
  title = {Fair Domain Generalization with Heterogeneous Sensitive Attributes Across Domains},
  booktitle = {2025 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  year = {2025},
  pages = {7389-7398},
  doi = {10.1109/WACV61041.2025.00718}
}
</pre></td>
</tr>
<tr id="D4TA08189G" class="entry">
	<td>Tawfik SA, La L, Nguyen TM, Tran T, Gupta S and Venkatesh S (2025), <i>"Scale matters: simulation of nanoscopic dendrite initiation in lithium solid electrolyte interphases using a machine learning potential"</i>, J. Mater. Chem. A.  Vol. 13, pp. 6357-6363. The Royal Society of Chemistry.
	<p class="infolinks">[<a href="javascript:toggleInfo('D4TA08189G','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('D4TA08189G','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1039/D4TA08189G" target="_blank">DOI</a>] [<a href="http://dx.doi.org/10.1039/D4TA08189G" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_D4TA08189G" class="abstract noshow">
	<td><b>Abstract</b>: Although lithium solid state electrolytes show promise in mitigating the chemical instabilities of liquid electrolytes in today's mainstream rechargeable batteries, solid state electrolytes still suffer from dendrite formation, which leads to battery degradation and short circuiting. Dendrite initiation and propagation in specific solid state electrolyte materials has been explained, at a microscopic scale, as emerging from the lithium filling of pores within the solid state electrolytes via microcracks. At the atomistic scale, the thermodynamic instability of many solid state electrolyte materials can explain their susceptibility to crystal decomposition upon contact with the lithium anode. However, for a more complete picture of the dendrite formation mechanisms, an understanding of the dendrite initiation mechanism at the intermediate nanoscopic scale is required. This work applies a machine learning potential (DIEP) for simulating six different solid state electrolyte–lithium interfaces at 300 K and 1000 K, with model sizes ranging from 18k to 36k atoms, for durations exceeding 20 ps. Our simulations show that the lithium dendrite initiation process can have an underpinning nanoscopic mechanism, in which the crystal decomposition by direct lithium interaction leads to the clustering of lithium. The simulations also suggest a possible mechanism for the creation of voids within the solid-electrolyte interphase, which have been observed in the Li|Li6PS5Cl|Li interface.</td>
</tr>
<tr id="bib_D4TA08189G" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{D4TA08189G,
  author = {Tawfik, Sherif Abdulkader and La, Linh and Nguyen, Tri Minh and Tran, Truyen and Gupta, Sunil and Venkatesh, Svetha},
  title = {Scale matters: simulation of nanoscopic dendrite initiation in lithium solid electrolyte interphases using a machine learning potential},
  journal = {J. Mater. Chem. A},
  publisher = {The Royal Society of Chemistry},
  year = {2025},
  volume = {13},
  pages = {6357-6363},
  url = {http://dx.doi.org/10.1039/D4TA08189G},
  doi = {10.1039/D4TA08189G}
}
</pre></td>
</tr>
<tr id="info:doi/10.2196/60413" class="entry">
	<td>Zheng WY, Shvetcov A, Slade A, Jenkins Z, Hoon L, Whitton A, Logothetis R, Ravindra S, Kurniawan S, Gupta S, Huckvale K, Stech E, Agarwal A, Funke Kupper J, Cameron S, Rosenberg J, Manoglou N, Senadeera M, Venkatesh S, Mouzakis K, Vasa R, Christensen H and Newby JM (2025), <i>"Recruiting Young People for Digital Mental Health Research: Lessons From an AI-Driven Adaptive Trial"</i>, J Med Internet Res., Jan, 2025.  Vol. 27, pp. e60413.
	<p class="infolinks">[<a href="javascript:toggleInfo('info:doi/10.2196/60413','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('info:doi/10.2196/60413','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.2196/60413" target="_blank">DOI</a>] [<a href="https://www.jmir.org/2025/1/e60413" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_info:doi/10.2196/60413" class="abstract noshow">
	<td><b>Abstract</b>: Background: With increasing adoption of remote clinical trials in digital mental health, identifying cost-effective and time-efficient recruitment methodologies is crucial for the success of such trials. Evidence on whether web-based recruitment methods are more effective than traditional methods such as newspapers, media, or flyers is inconsistent. Here we present insights from our experience recruiting tertiary education students for a digital mental health artificial intelligence--driven adaptive trial---Vibe Up. Objective: We evaluated the effectiveness of recruitment via Facebook and Instagram compared to traditional methods for a treatment trial and compared different recruitment methods' retention rates. With recruitment coinciding with COVID-19 lockdowns across Australia, we also compared the cost-effectiveness of social media recruitment during and after lockdowns. Methods: Recruitment was completed for 2 pilot trials and 6 minitrials from June 2021 to May 2022. To recruit participants, paid social media advertising on Facebook and Instagram was used, alongside mailing lists of university networks and student organizations or services, media releases, announcements during classes and events, study posters or flyers on university campuses, and health professional networks. Recruitment data, including engagement metrics collected by Meta (Facebook and Instagram), advertising costs, and Qualtrics data on recruitment methods and survey completion rates, were analyzed using RStudio with R (version 3.6.3; R Foundation for Statistical Computing). Results: In total, 1314 eligible participants (aged 22.79, SD 4.71 years; 1079, 82.1% female) were recruited to 2 pilot trials and 6 minitrials. The vast majority were recruited via Facebook and Instagram advertising (n=1203; 92%). Pairwise comparisons revealed that the lead institution's website was more effective in recruiting eligible participants than Facebook (z=3.47; P=.003) and Instagram (z=4.23; P<.001). No differences were found between recruitment methods in retaining participants at baseline, at midpoint, and at study completion. Wilcoxon tests found significant differences between lockdown (pilot 1 and pilot 2) and postlockdown (minitrials 1-6) on costs incurred per link click (lockdown: median Aus &dollar;0.35 [US &dollar;0.22], IQR Aus &dollar;0.27-&dollar;0.47 [US &dollar;0.17-&dollar;0.29]; postlockdown: median Aus &dollar;1.00 [US &dollar;0.62], IQR Aus &dollar;0.70-&dollar;1.47 [US &dollar;0.44-&dollar;0.92]; W=9087; P<.001) and the amount spent per hour to reach the target sample size (lockdown: median Aus &dollar;4.75 [US &dollar;2.95], IQR Aus &dollar;1.94-6.34 [US &dollar;1.22-&dollar;3.97]; postlockdown: median Aus &dollar;13.29 [US &dollar;8.26], IQR Aus &dollar;4.70-25.31 [US &dollar;2.95-&dollar;15.87]; W=16044; P<.001). Conclusions: Social media advertising via Facebook and Instagram was the most successful strategy for recruiting distressed tertiary students into this artificial intelligence--driven adaptive trial, providing evidence for the use of this recruitment method for this type of trial in digital mental health research. No recruitment method stood out in terms of participant retention. Perhaps a reflection of the added distress experienced by young people, social media recruitment during the COVID-19 lockdown period was more cost-effective. Trial Registration: Australian New Zealand Clinical Trials Registry ACTRN12621001092886; https://tinyurl.com/39f2pdmd;  Australian New Zealand Clinical Trials Registry ACTRN12621001223820; https://tinyurl.com/bdhkvucv</td>
</tr>
<tr id="bib_info:doi/10.2196/60413" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{info:doi/10.2196/60413,
  author = {Zheng, Wu Yi and Shvetcov, Artur and Slade, Aimy and Jenkins, Zoe and Hoon, Leonard and Whitton, Alexis and Logothetis, Rena and Ravindra, Smrithi and Kurniawan, Stefanus and Gupta, Sunil and Huckvale, Kit and Stech, Eileen and Agarwal, Akash and Funke Kupper, Joost and Cameron, Stuart and Rosenberg, Jodie and Manoglou, Nicholas and Senadeera, Manisha and Venkatesh, Svetha and Mouzakis, Kon and Vasa, Rajesh and Christensen, Helen and Newby, Jill M},
  title = {Recruiting Young People for Digital Mental Health Research: Lessons From an AI-Driven Adaptive Trial},
  journal = {J Med Internet Res},
  year = {2025},
  volume = {27},
  pages = {e60413},
  url = {https://www.jmir.org/2025/1/e60413},
  doi = {10.2196/60413}
}
</pre></td>
</tr>
<tr id="info:doi/10.2196/63126" class="entry">
	<td>Holmes G, Tang B, Gupta S, Venkatesh S, Christensen H and Whitton A (2025), <i>"Applications of Large Language Models in the Field of Suicide Prevention: Scoping Review"</i>, J Med Internet Res., Jan, 2025.  Vol. 27, pp. e63126.
	<p class="infolinks">[<a href="javascript:toggleInfo('info:doi/10.2196/63126','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('info:doi/10.2196/63126','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.2196/63126" target="_blank">DOI</a>] [<a href="https://www.jmir.org/2025/1/e63126" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_info:doi/10.2196/63126" class="abstract noshow">
	<td><b>Abstract</b>: Background: Prevention of suicide is a global health priority. Approximately 800,000 individuals die by suicide yearly, and for every suicide death, there are another 20 estimated suicide attempts. Large language models (LLMs) hold the potential to enhance scalable, accessible, and affordable digital services for suicide prevention and self-harm interventions. However, their use also raises clinical and ethical questions that require careful consideration. Objective: This scoping review aims to identify emergent trends in LLM applications in the field of suicide prevention and self-harm research. In addition, it summarizes key clinical and ethical considerations relevant to this nascent area of research. Methods: Searches were conducted in 4 databases (PsycINFO, Embase, PubMed, and IEEE Xplore) in February 2024. Eligible studies described the application of LLMs for suicide or self-harm prevention, detection, or management. English-language peer-reviewed articles and conference proceedings were included, without date restrictions. Narrative synthesis was used to synthesize study characteristics, objectives, models, data sources, proposed clinical applications, and ethical considerations. This review adhered to the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) standards. Results: Of the 533 studies identified, 36 (6.8%) met the inclusion criteria. An additional 7 studies were identified through citation chaining, resulting in 43 studies for review. The studies showed a bifurcation of publication fields, with varying publication norms between computer science and mental health. While most of the studies (33/43, 77%) focused on identifying suicide risk, newer applications leveraging generative functions (eg, support, education, and training) are emerging. Social media was the most common source of LLM training data. Bidirectional Encoder Representations from Transformers (BERT) was the predominant model used, although generative pretrained transformers (GPTs) featured prominently in generative applications. Clinical LLM applications were reported in 60% (26/43) of the studies, often for suicide risk detection or as clinical assistance tools. Ethical considerations were reported in 33% (14/43) of the studies, with privacy, confidentiality, and consent strongly represented. Conclusions: This evolving research area, bridging computer science and mental health, demands a multidisciplinary approach. While open access models and datasets will likely shape the field of suicide prevention, documenting their limitations and potential biases is crucial. High-quality training data are essential for refining these models and mitigating unwanted biases. Policies that address ethical concerns---particularly those related to privacy and security when using social media data---are imperative. Limitations include high variability across disciplines in how LLMs and study methodology are reported. The emergence of generative artificial intelligence signals a shift in approach, particularly in applications related to care, support, and education, such as improved crisis care and gatekeeper training methods, clinician copilot models, and improved educational practices. Ongoing human oversight---through human-in-the-loop testing or expert external validation---is essential for responsible development and use. Trial Registration: OSF Registries osf.io/nckq7; https://osf.io/nckq7</td>
</tr>
<tr id="bib_info:doi/10.2196/63126" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{info:doi/10.2196/63126,
  author = {Holmes, Glenn and Tang, Biya and Gupta, Sunil and Venkatesh, Svetha and Christensen, Helen and Whitton, Alexis},
  title = {Applications of Large Language Models in the Field of Suicide Prevention: Scoping Review},
  journal = {J Med Internet Res},
  year = {2025},
  volume = {27},
  pages = {e63126},
  url = {https://www.jmir.org/2025/1/e63126},
  doi = {10.2196/63126}
}
</pre></td>
</tr>
<tr id="PATIL2025111698" class="entry">
	<td>Patil PW, Randive SN, Gupta S, Rana S, Venkatesh S and Murala S (2025), <i>"Unpaired recurrent learning for real-world video de-hazing"</i>, Pattern Recognition.  Vol. 166, pp. 111698.
	<p class="infolinks">[<a href="javascript:toggleInfo('PATIL2025111698','abstract')">Abstract</a>] [<a href="javascript:toggleInfo('PATIL2025111698','bibtex')">BibTeX</a>] [<a href="https://doi.org/10.1016/j.patcog.2025.111698" target="_blank">DOI</a>] [<a href="https://www.sciencedirect.com/science/article/pii/S0031320325003589" target="_blank">URL</a>]</p>
	</td>
</tr>
<tr id="abs_PATIL2025111698" class="abstract noshow">
	<td><b>Abstract</b>: Automated outdoor vision-based applications have become increasingly in demand for day-to-day life. Bad weather like haze, rain, snow, etc. may limit the reliability of these applications due to degradation in the overall video quality. So, there is a dire need to pre-process the weather-degraded videos before they are fed to downstream applications. Researchers generally adopt synthetically generated paired hazy frames for learning the task of video de-hazing. The models trained solely on synthetic data may have limited performance on different types of real-world hazy scenarios due to significant domain gap between synthetic and real-world hazy videos. One possible solution is to prove the generalization ability by training on unpaired data for video de-hazing. Some unpaired learning approaches are proposed for single image de-hazing. However, these unpaired single image de-hazing approaches compromise the performance in terms of temporal consistency, which is important for video de-hazing tasks. With this motivation, we have proposed a lightweight and temporally consistent architecture for video de-hazing tasks. To achieve this, diverse receptive and multi-scale features at various input resolutions are mixed and aggregated with multi-kernel attention to extract significant haze information. Furthermore, we propose a recurrent multi-attentive feature alignment concept to maintain temporal consistency with recurrent feedback of previously restored frames for temporal consistent video restoration. Comprehensive experiments are conducted on real-world and synthetic video databases (REVIDE and RSA100Haze). Both the qualitative and quantitative results show significant improvement of the proposed network with better temporal consistency over state-of-the-art methods for detailed video restoration in hazy weather. Source code is available at: https://github.com/pwp1208/UnpairedVideoDehazing.</td>
</tr>
<tr id="bib_PATIL2025111698" class="bibtex noshow">
<td><b>BibTeX</b>:
<pre>
@article{PATIL2025111698,
  author = {Prashant W. Patil and Santosh Nagnath Randive and Sunil Gupta and Santu Rana and Svetha Venkatesh and Subrahmanyam Murala},
  title = {Unpaired recurrent learning for real-world video de-hazing},
  journal = {Pattern Recognition},
  year = {2025},
  volume = {166},
  pages = {111698},
  url = {https://www.sciencedirect.com/science/article/pii/S0031320325003589},
  doi = {10.1016/j.patcog.2025.111698}
}
</pre></td>
</tr>
</tbody>
</table>
<footer>
 <small>Created by <a href="http://jabref.sourceforge.net">JabRef</a> on 28/05/2025.</small>
</footer>
<!-- file generated by JabRef -->
</body>
</html>